---
title: UMAP vs t-SNE
date: '2026-01-06'
summary: 'What they optimize, when to use them and when not to.'
---

<script lang="ts">
export const meta = {
    title: "{title}",
    date: "{date}",
    summary: "{summary}"
  };
</script>

# {title}


![Image](https://www.researchgate.net/profile/Chuck-Grace/publication/341231042/figure/fig10/AS%3A1026960872448002%401621857960386/t-SNE-visualization-for-the-full-dataset-by-cluster-projected-onto-two-embeddings.ppm)

![Image](https://umap-learn.readthedocs.io/en/latest/_images/20newsgroups_hellinger_counts.png)

![Image](https://projector.tensorflow.org/preview.png)

![Image](https://biostatsquid.com/wp-content/uploads/2025/03/Slide89.png)

# The invisible backbone of AI systems: UMAP, t-SNE, and why your plots lie (sometimes)

When people think about **Artificial Intelligence**, they usually picture large models, GPUs, and inference pipelines.

What they rarely think about is **how we *look* at high-dimensional representations**.

Yet dimensionality reduction techniques like **t-SNE** and **UMAP** are everywhere in serious AI systems. Not in production inference—but deeply embedded in **analytical, validation, and monitoring workflows** at companies such as Google, Meta, Amazon, or Netflix.

They are not “just visualization tools”.
They are **diagnostic instruments**.

And like any instrument, they are dangerous if you don’t understand what they measure.

## Where t-SNE and UMAP are actually used in real systems

Before diving into the math, it’s worth grounding this in reality.

### Embedding visualization and validation

This is probably the most common use case today:

* validating embedding quality
* detecting representation collapse
* spotting unexpected clusters
* identifying noise, bias, or drift

A canonical example: **Google uses t-SNE inside TensorBoard** to explore word, image, and multimodal embeddings during training.

Here, the question is not *“what is the true structure?”*
It’s *“does this representation behave as expected?”*

### Bioinformatics and genomics

In biology, dimensionality reduction is not optional—it’s foundational.

Typical applications include:

* cell type identification
* discovery of cellular states
* validation of biological clusters
* exploratory analysis of single-cell RNA-seq data

In this domain, UMAP and t-SNE are often used **before** any downstream statistical modeling, as a way to generate hypotheses rather than confirm them.

### Cybersecurity and fraud detection

In security-critical systems:

* transaction embeddings
* user behavior vectors
* network traffic fingerprints

are often projected to 2D or 3D to support:

* exploratory fraud analysis
* decision support for human analysts
* detection of anomalous behavior
* incident investigation

No one deploys t-SNE in a fraud decision engine—but many fraud decisions *start* with a visualization.

### Model monitoring in production

In mature ML platforms, embeddings are monitored just like metrics:

* Are new embeddings drifting?
* Are clusters collapsing or fragmenting?
* Are rare patterns becoming common?

Dimensionality reduction becomes a **monitoring lens**, not a model.

## The recurring mistake: trusting the picture too much

This has probably happened to you:

You run **UMAP** or **t-SNE**, you see clean clusters, and you think:

> “There’s clear structure in the data.”

Sometimes there is.

Very often, there isn’t—not in the way the picture suggests.

This is not because the algorithms are flawed.
It’s because **we misinterpret what they are optimizing**.

## The shared intuition (no equations… yet)

Both **t-SNE** and **UMAP** start from the same core idea:

> In high dimensions, some points are neighbors.
> In 2D, those neighbors should *still* be neighbors.

That’s the entire premise.

They do **not** attempt to:

* preserve absolute distances
* preserve angles or volumes
* preserve global geometry
* preserve cluster size or density

They optimize **neighborhood consistency**.

Everything else is negotiable.

## t-SNE: a magnifying glass for local structure

*(Distill, 2016)*

At a high level, t-SNE works as follows:

1. Measure pairwise distances in high-dimensional space
2. Convert those distances into **probabilities of neighborhood membership**
3. Do the same in the low-dimensional space
4. Move points to make those two probability distributions match

Formally, it minimizes a **Kullback–Leibler divergence**:

$$
KL(P \parallel Q)
$$

Here is the critical insight—one that explains **most misinterpretations**:

* The KL divergence **strongly penalizes losing close neighbors**
* It is largely indifferent to errors involving far-away points

As a consequence:

* distances *between* clusters are meaningless
* cluster size is meaningless
* empty space is meaningless

This is why Distill famously warns that t-SNE plots are **not maps**.

They are **magnifying glasses**.

They answer:

> “Which points are locally similar?”

They do *not* answer:

> “How different are these groups?”

## UMAP: similar goal, different assumptions

*(McInnes et al., 2018 · Google PAIR)*

UMAP begins with a stronger modeling assumption:

> The data lies on (or near) a low-dimensional manifold.

From that assumption, it builds a **fuzzy neighbor graph** where:

* each point connects to its neighbors
* each connection has a strength
* closer points → stronger connections

These strengths are expressed as probabilities, conceptually of the form:

$$
p_{ij} = \exp\left(-\frac{d(x_i, x_j) - \rho_i}{\sigma_i}\right)
$$

You don’t need the formula to understand the intuition:

> “Local distances matter a lot.
> Global distances matter less.”

UMAP then places points in low dimensions by minimizing a **cross-entropy** between the high-dimensional and low-dimensional graphs.

Important consequences:

* UMAP does **not** preserve variance (unlike PCA)
* It preserves **topological relationships**
* It encodes assumptions about continuity and locality

This is why UMAP often “looks better” than t-SNE—
but also why it can feel *more convincing than it should*.

## Why one parameter can change everything

This is where the **Google PAIR guide** and the **2021 instability paper** align perfectly.

Parameters like:

* `n_neighbors`
* `min_dist`
* distance metric
* random initialization

are **not implementation details**.

They are **assumptions about reality**.

Changing `n_neighbors` is equivalent to changing the question:

> “What does *local* mean in this dataset?”

Mathematically:

* the optimization problem is **non-convex**
* there are many valid minima
* different seeds → different solutions

The 2021 paper demonstrates that:

> Small perturbations can produce radically different embeddings

Not because UMAP or t-SNE are unstable toys—
but because **there is no single correct 2D representation**.

## When these tools are genuinely valuable

Used correctly, they are incredibly powerful:

* exploring embedding spaces
* detecting unusual neighborhoods
* debugging representation learning
* identifying dataset pathologies
* generating hypotheses

They shine in:

* text embeddings
* image embeddings
* multimodal representations
* exploratory analysis before modeling

They help humans **see failure modes** that metrics alone may miss.

## When you should be very cautious

They become dangerous when used to:

* decide how many clusters exist
* justify strategic or business decisions
* measure real similarity or distance
* “prove” structure in the data

If your conclusion collapses when you:

* change parameters
* change the random seed
* subsample the data

then the conclusion was never robust.

## A rule of thumb that almost never fails

* **PCA** → understand variance and linear structure
* **t-SNE** → inspect *local* relationships
* **UMAP** → explore local structure at scale
* **Metrics + domain knowledge** → decide

Visualizations are **tools for thinking**, not evidence.

## Closing thoughts

All the referenced resources—academic papers and practitioner guides alike—converge on the same idea:

> Dimensionality reduction does not *discover* structure.
> It **optimizes a notion of structure**.

The difference between a junior and a senior practitioner is not knowing how to run UMAP.

It’s knowing **when the picture helps… and when it lies**.

## References

* **UMAP: Uniform Manifold Approximation and Projection**
  [https://arxiv.org/abs/1802.03426](https://arxiv.org/abs/1802.03426)

* **On the instability and misinterpretation of dimensionality reduction visualizations**
  [https://arxiv.org/abs/2102.01384](https://arxiv.org/abs/2102.01384)

* **How to Use t-SNE Effectively**
  [https://distill.pub/2016/misread-tsne/](https://distill.pub/2016/misread-tsne/)

* **Google PAIR** — *Understanding UMAP*
  [https://pair-code.github.io/understanding-umap/](https://pair-code.github.io/understanding-umap/)

  <style>
  
  img {
    width: 80%;
  }

  </style>
