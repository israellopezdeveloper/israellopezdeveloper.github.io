{
  "educations": {
    "complementary": [
      {
        "images": ["linux_foundation.png"],
        "institution": "The Linux Foundation",
        "period_time": {
          "current": true,
          "end": "None of them",
          "start": "In September 2015"
        },
        "summary": "Perform advanced management of block storage and file systems, as well as advanced network authentication and system security, including firewall and VPN. Install and configure central network services (DHCP, DNS, SSH, web servers, file servers, email, etc.).",
        "thumbnail": "linux_foundation.png",
        "title": "This Regulation shall enter into force on the twentieth day following that of its publication in the Official Journal."
      },
      {
        "images": ["linux_foundation.png"],
        "institution": "The Linux Foundation",
        "period_time": {
          "current": true,
          "end": "None of them",
          "start": "In September 2013"
        },
        "summary": "Official Linux system administration certification that involves qualification for: Install a Linux system, including X11 and configure it as a network client. Manage files and access permissions, including ACL, as well as system security.",
        "thumbnail": "linux_foundation.png",
        "title": "This Regulation shall enter into force on the twentieth day following that of its publication in the Official Journal."
      },
      {
        "images": ["uah.svg"],
        "institution": "University of Alcalá de Henares",
        "period_time": {
          "current": true,
          "end": "None of them",
          "start": "In September 2007"
        },
        "summary": "Design of educational content through the SCORM standard.",
        "thumbnail": "uah.svg",
        "title": "Design and evaluation of digital educational content"
      },
      {
        "images": ["uah.svg"],
        "institution": "University of Alcalá de Henares",
        "period_time": {
          "current": true,
          "end": "None of them",
          "start": "In September 2007"
        },
        "summary": "Artificial vision systems, winding arrays, filters.",
        "thumbnail": "uah.svg",
        "title": "Artificial vision course"
      }
    ],
    "languages": [
      {
        "acreditation": [],
        "language": "Spanish",
        "read": "Native",
        "spoken": "Native",
        "thumbnail": "spanish.png",
        "writen": "Native"
      },
      {
        "acreditation": [],
        "language": "English",
        "read": "Fluid",
        "spoken": "Fluid",
        "thumbnail": "english.svg",
        "writen": "Fluid"
      },
      {
        "acreditation": [
          {
            "institution": "Confucius Institute of Madrid",
            "period_time": {
              "current": true,
              "end": "None of them",
              "start": "In September 2009"
            },
            "title": "HSK 3"
          }
        ],
        "language": "Chinese",
        "read": "Fluid",
        "spoken": "Fluid",
        "thumbnail": "chinese.png",
        "writen": "Fluid"
      }
    ],
    "university": [
      {
        "images": ["uah.svg"],
        "period_time": {
          "current": false,
          "end": "June 2009",
          "start": "In September 2007"
        },
        "summary": "Artificial intelligence and machine learning. Symbolic learning. Classification and regression models. Deep networks. Multilayer networks, retropropagation. Hyperparameters and learning strategies. Convoltional networks. Sequential and recurrent networks. Parallelisation and computing techniques in GPU-based architectures. Automated learning.",
        "thumbnail": "uah.svg",
        "title": "Master's degree in Artificial Intelligence in information and communication technologies",
        "university_name": "A.U.A."
      },
      {
        "images": ["uah.svg"],
        "period_time": {
          "current": false,
          "end": "June 2007",
          "start": "September 2001"
        },
        "summary": "With honors in: Artificial intelligence, diffuse logic, systems of artificial vision, physics II, mathematical analysis, data structure, networks.",
        "thumbnail": "uah.svg",
        "title": "Technical engineering in computer science",
        "university_name": "A.U.A."
      }
    ]
  },
  "intro": {
    "bio": [
      {
        "dates": "1983",
        "text": "I was born in Madrid, Spain"
      },
      {
        "dates": "2007 and 2007",
        "text": "Completed his bachelor's degree in Computer Science at the University of Alcalá de Henares"
      },
      {
        "dates": "2009 and 2009",
        "text": "He completed his Master's degree in Artificial Intelligence in Information and Communication Technologies at the University of Alcalá de Henares."
      },
      {
        "dates": "2004 to the present",
        "text": "Working as an employee"
      }
    ],
    "greeting": "Hello, I'm Israel, a hardened senior developer traveling the world.",
    "hobbies": " climbing,  snowboarding,  traveling,  diving,  mathematics (especially linear algebra and statistics),  Artificial intelligence.",
    "links": [
      {
        "icon": "",
        "text": "@israellopezdeveloper",
        "url": "https://github.com/israellopezdeveloper"
      },
      {
        "icon": "󰇮",
        "text": "israel.lopez.developer@gmail.com",
        "url": "mailto:israel.lopez.developer@gmail.com"
      },
      {
        "icon": "󰌻",
        "text": "https://www.linkedin.com/in/israellopezmaiz/",
        "url": "https://www.linkedin.com/in/israellopezmaiz/"
      },
      {
        "icon": "",
        "text": "+34 648 13 66 40",
        "url": "tel:+34648136640"
      }
    ],
    "name": "Israel López",
    "profile_image": "israel.png",
    "summary": "<p>I've been bitten by the programming worm since I was 13 and I couldn't stop anywhere in the world with my laptop under my arm! I consider myself a restless mind because of my insatiable desire to learn, innovate and overcome new intellectual challenges. I'm lucky that programming is not only my job, it's also my passion, and if there's anything that characterizes me, it's my insistence on finding the optimal solution to the project, because yes, I'm proud to deliver clean, efficient code.</p>",
    "title": "Senior Software Engineer"
  },
  "works": [
    {
      "contribution": "<p>Optimization of the deployment cycle of models in distributed environments, reducing production time. Implementation of modules in Python and Rust for model management, monitoring and fault recovery. Optimization of GPU and CPU usage to maximize energy efficiency.</p>",
      "full_description": "<p>Date and time is a company specializing in the development of technologies for the distribution and execution of AI models in decentralized networks and distributed environments. Its goal is to eliminate the limitations of centralized systems, offering tools that allow AI models to be deployed in a secure, fast and scalable manner, both in the cloud and on remote devices. Its main product, Celium , is a platform for orchestrating and managing AI models in containers. Use templates optimized for models such as Stable Diffusion, Whisper, LLaMA or Mistral.</p>",
      "images": [],
      "links": [
        {
          "icon": "",
          "text": "Web site",
          "url": "https://www.datura.ai"
        }
      ],
      "name": "Datura AI",
      "period_time": {
        "current": true,
        "end": "None of them",
        "start": "March 2025"
      },
      "projects": [
        {
          "description": "<p>In this task, I focused on optimizing the platform's reward system, which aims to incentivize the nodes that actually offer the best performance within the network. From this analysis, I established a new scoring system that gives greater relevance to continuous availability, progressively penalizes interruptions or excessive model change times, and favors nodes that manage to maintain a stable and predictable service. To reinforce system fairness, it also introduced control mechanisms against manipulation attempts or opportunistic behaviours, ensuring that reward accumulation depends not only on the volume of tasks, but on the actual quality with which they are executed. Thanks to this improvement, the rewards system now aligns incentives much better with Celium's goals: nodes that ensure high availability, low latency and minimum transition times between models receive recognition proportional to their contribution, which encourages collaboration, stability and overall efficiency of distributed infrastructure.</p>",
          "images": [],
          "links": [
            {
              "icon": "",
              "text": "Portal of Celium",
              "url": "https://lium.io/"
            }
          ],
          "name": "Improvement of the reward algorithm in performance",
          "technologies": [
            "Prometheus",
            "Bittensor",
            "Tech",
            "CUDA",
            "GPU Computing",
            "GitHub Actions",
            "Git",
            "Helm",
            "Kubernetes",
            "Docker",
            "C",
            "Rust",
            "Python",
            "FastAPI",
            "Redis",
            "PostgreSQL",
            "Celery",
            "Grafana"
          ]
        },
        {
          "description": "<p>I implemented a platform of instantaneous deployment of Machine Learning models in containers , operational in on-premises , public cloud and edge . The design prioritizes portability, low latency and scalability, enabling models to be published and updated securely with minimal service interruption. The solution incorporates dynamic management of resources with real-time pod editing and Hot reassignment of CPU, GPU and memory This enables efficient use of infrastructure and reduces time to production new models, while maintaining system stability and cost-effectiveness. The responsibilities Design and implement container infrastructure for deployment of models in multiple environments (local, cloud and edge). Enable the editing of pods and the Hot reassignment CPU, GPU and memory without noticeable downtime.</p>",
          "images": [],
          "links": [],
          "name": "Dynamic deployment and management of models",
          "technologies": [
            "Docker",
            "Kubernetes",
            "Helm",
            "CUDA",
            "TensorRT",
            "gRPC",
            "GitHub Actions",
            "GPU Computing",
            "Python"
          ]
        },
        {
          "description": "<p>I developed processes for automatic updating and distribution of models In this context, the Commission's proposal for a Directive on the approximation of the laws of the Member States on the approximation of the laws of the Member States on the approximation of the laws of the Member States on the approximation of the laws of the Member States on the approximation of the laws of the Member States on the approximation of the laws of the Member States on the approximation of the laws of the Member States on the approximation of the laws of the Member States on the approximation of the laws of the Member States on the approximation of the laws of the Member States on the approximation of the laws of the Member States on the approximation of the laws of the Member States. This strategy drastically reduced the spread times of new versions and strengthened the system resilience , ensuring continuity in large-scale distributed environments. The responsibilities Design automation flows for updating and deploying models in distributed environments. Reducing the spread time of new versions through optimized CI/CD pipelines.</p>",
          "images": [],
          "links": [],
          "name": "Automation and scalability",
          "technologies": [
            "Ansible",
            "Terraform",
            "Kafka",
            "MinIO",
            "Bash",
            "Git"
          ]
        },
        {
          "description": "<p>Real-time metrics This has led to increased visibility of the system and improved the ability to diagnose and resolve early incidents on the platform. I applied advanced techniques to Weighing of loads and Affinity of processes , aimed at optimising energy efficiency and maximizing the performance of the hardware available in distributed environments. The responsibilities Design and implement real-time metrics collection for CPU, GPU, memory and inference latency. Set up process affinity and anti-affinity policies to optimize the use of hardware.</p>",
          "images": [],
          "links": [],
          "name": "Monitoring and performance",
          "technologies": [
            "Prometheus",
            "Grafana",
            "Elastic Stack",
            "Elastic Search",
            "Logstash",
            "Kibana",
            "Node Exporter",
            "cAdvisor",
            "NginX"
          ]
        },
        {
          "description": "<p>I contributed to integration of Celium with decentralised networks as Bittensor, expanding the platform's capabilities and enhancing its interoperability in distributed and collaborative environments. This integration made it possible to leverage decentralized infrastructure for resource exchange and model deployment, strengthening the scalability and resilience of the ecosystem. The responsibilities Design and implement connectors between Celium and decentralized networks such as Bittensor. Collaborate with research teams to explore new use cases of interoperability in decentralized AI.</p>",
          "images": [],
          "links": [],
          "name": "Interoperability with decentralised ecosystems",
          "technologies": [
            "Kubernetes",
            "Docker",
            "Polkadot.js",
            "Substrate API",
            "Web3",
            "ONNX Runtime",
            "PyTorch",
            "Bittensor"
          ]
        }
      ],
      "short_description": "<p>Its mission is to build solutions that surpass centralized systems, offering easy-to-use tools and high performance. Celium , a platform for instantaneous deployment of AI models in containers, enabling pod editing, deployment templates, and rapid execution of models such as Stable Diffusion or Whisper.</p>",
      "thumbnail": "daturaai.png"
    },
    {
      "contribution": "<p>In Indra I participated in the following key areas: Backend design and implementation in Java and Node.js with Clean Architecture principles to achieve sustainability and scalability. Integration of an RAG system for contextual recovery of operational intelligence: heterogeneous intake, embeddings and semantic search. GIS capabilities for geospatial analysis, tactical visualization and real-time route/deployment optimization. Definition of API and interfaces to interact with NATO systems, complying with safe standards and protocols.</p>",
      "full_description": "<p>In the field of Defence, Indra is leading the development of the first next-generation mission system for military vehicles from Europe and NATO countries, a pioneering project that seeks to provide the armed forces with an open, modular and scalable platform that integrates sensors, communication systems, AI capabilities and GIS components to optimize decision-making in complex operational environments. I worked on this project as a Senior Software Engineer, contributing to the definition, development and integration of critical components into a technological ecosystem that combined Java, Node.js, Python, Augmented Information Recovery (RAG) systems and GIS.</p>",
      "images": [],
      "links": [],
      "name": "Indra",
      "period_time": {
        "current": false,
        "end": "February 2025",
        "start": "April 2024"
      },
      "projects": [
        {
          "description": "<p>Strategic project developed by Indra within the framework of the European Defence Fund to create the first new generation mission system for military vehicles from Europe and NATO countries . The system integrates AI, GIS and sensor management capabilities to provide the armed forces with a tactical advantage in complex operational environments. The architecture is open, modular and scalable, enabling interoperability between allied armies and the rapid integration of new technological components. RAG system for contextual information retrieval, real-time geospatial analysis, and secure communication modules for the transmission of critical data. Development and integration of an RAG system for semantic search and contextualization of operational data.</p>",
          "images": [],
          "links": [
            {
              "icon": "",
              "text": "Indra's participation in the European Defence Fund",
              "url": "https://www.indracompany.com/es/noticia/indra-lidera-participacion-espanola-proyectos-fondo-europeo-defensa-entra-formar-12"
            }
          ],
          "name": "New generation mission system for military vehicles",
          "technologies": [
            "Java",
            "Spring Boot",
            "Spring Data",
            "Spring Security",
            "Node.js",
            "Express",
            "Python",
            "FastAPI",
            "RAG",
            "Vector DB",
            "Embeddings",
            "PostgreSQL",
            "MongoDB",
            "GIS",
            "PostGIS",
            "OpenLayers",
            "Docker",
            "Kubernetes",
            "Helm",
            "GitHub Actions",
            "Jira",
            "Prometheus",
            "Grafana"
          ]
        },
        {
          "description": "<p>I actively participated in the integration of Augmented Information Recovery (RAG) systems with the aim of improving the mission system's ability to access critical information in real time. My work consisted of designing and developing pipelines that would allow data from multiple heterogeneous sources to be ingested, processed and consulted, ensuring that the recovered information was always relevant, accurate and available with low latency.</p>",
          "images": [],
          "links": [],
          "name": "Integration of enhanced information retrieval (RAG) systems",
          "technologies": [
            "Java",
            "Spring Security",
            "Spring Data",
            "Node Exporter",
            "Python",
            "Elastic Search",
            "Qdrant",
            "LangChain",
            "PostgreSQL",
            "Docker",
            "Kubernetes"
          ]
        },
        {
          "description": "<p>I collaborated in the creation of services that allowed real-time data processing, including satellite image analysis, video pattern recognition and natural language processing for the automatic extraction of relevant information. My contribution included implementing pipelines of training and model deployment, converting models to GPU-optimized formats and limited resource environments, and integrating APIs that connected these AI modules with the rest of the platform ecosystem.</p>",
          "images": [],
          "links": [],
          "name": "Collaboration in Artificial Intelligence modules",
          "technologies": [
            "Python",
            "PyTorch",
            "Bittensor",
            "Hugging Face Transformers",
            "OpenCV",
            "CUDA",
            "ONNX Runtime",
            "FastAPI",
            "Grafana",
            "Docker"
          ]
        },
        {
          "description": "<p>I will lead and participate in complex integration testing, ensuring that the different system modules communicate correctly in distributed and mission-critical environments.My work included defining test scenarios, creating continuous integration pipelines, and validating the interoperability of services deployed in both local and cloud infrastructures. I also contributed to the design and execution of deployments using container orchestrators and automation tools, in order to ensure the scalability, resilience and security of the platform.</p>",
          "images": [],
          "links": [],
          "name": "Integration and deployment testing in distributed environments",
          "technologies": [
            "Jenkins",
            "Git",
            "Docker",
            "Kubernetes",
            "Helm",
            "Ansible",
            "Terraform",
            "Prometheus",
            "Grafana"
          ]
        }
      ],
      "short_description": "It offers innovative solutions for sectors such as Defence, Transport, Energy, Security and Digital Transformation. In the field of Defence, it develops strategic and mission-critical systems that strengthen the technological autonomy and interoperability of the armed forces of Europe and NATO allies.",
      "thumbnail": "indra.png"
    },
    {
      "contribution": "<p>At Devo, I played a crucial role in the data intake team, focusing specifically on the load balancer. In addition, I contributed significantly to Devo's efforts to adapt to the standards needed for integration with U.S. I also participated in the creation of a multi-regional and multicloud backup system, ensuring the redundancy and reliability of data in diverse environments.</p>",
      "full_description": "<p>Devo is a leading enterprise in cloud-based registry and native security analytics, dedicated to providing real-time insights and advanced analytics for enterprise data. Serving a wide range of industries, including finance and telecommunications, Devo improves cybersecurity measures and optimizes data management practices, helping enterprises stay ahead of evolving threats and regulatory requirements.</p>",
      "images": ["devo1.png", "devo2.png"],
      "links": [
        {
          "icon": "",
          "text": "Web site of Devo",
          "url": "https://www.devo.com/es/"
        }
      ],
      "name": "Devo",
      "period_time": {
        "current": false,
        "end": "March 2024",
        "start": "March 2020"
      },
      "projects": [
        {
          "description": "<p>I contributed significantly to improving the performance of Devo's load balancer by implementing advanced strategies that improved fault tolerance and optimized monitoring of data entry services. I meticulously analyzed system requirements and identified key areas for improvement, ensuring that the load balancer could handle variable traffic levels more efficiently. I also developed methods to balance customer-based load, which facilitated more compact data queries. My contributions led to a more robust and responsive load balancing system, significantly improving performance and user experience at Devo.</p>",
          "images": [],
          "links": [
            {
              "icon": "",
              "text": "Documentation of the load balancer",
              "url": "https://docs.devo.com/space/latest/94653692/Event+load+balancers"
            }
          ],
          "name": "Improvement of the existing load balancer",
          "technologies": [
            "BDD",
            "TDD",
            "Jira",
            "GIT",
            "Kubernetes",
            "Gitlab CI/CD",
            "Jenkins",
            "Owasp",
            "Snyk",
            "SonarQube",
            "FedRAMP",
            "FIPS",
            "C++",
            "C",
            "Node.js"
          ]
        },
        {
          "description": "<p>One of the key features of this system was its ability to configure real-time storage types, allowing fluid adjustments to cloud storage configurations based on real-time needs and criteria. I implemented sophisticated data transition criteria, which automated the movement of data between different types of storage based on usage patterns and retention policies. To further improve system efficiency, I developed advanced data compression methods for data that were near the end of their useful life, optimizing storage usage and reducing overload. My contributions to this multicloud backup system not only strengthened Devo's data management capabilities but also ensured compliance with strict security and data retention regulations. This project highlighted my experience in creating resilient, scalable, and highly efficient data storage solutions, reinforcing Devo's commitment to excellence in security and data analytics.</p>",
          "images": [],
          "links": [],
          "name": "Creating a multicloud backup system",
          "technologies": [
            "BDD",
            "TDD",
            "Jira",
            "GIT",
            "Kubernetes",
            "Gitlab CI/CD",
            "Jenkins",
            "Owasp",
            "Snyk",
            "SonarQube",
            "FedRAMP",
            "FIPS",
            "GCP",
            "AWS",
            "Java"
          ]
        },
        {
          "description": "<p>I played a key role in integrating comprehensive quality and safety reviews into Devo's CI/CD pipeline. Integration of the Jenkins Pipeline Initially, I focused on incorporating SonarQube into the Jenkins pipeline for continuous code quality analysis. I configured SonarQube to perform static code analysis, which allowed the team to detect code odors, errors, and potential vulnerabilities early in the development cycle. Transition to GitLab CI/CD After the success with Jenkins, I made the transition from the pipeline to GitLab CI/CD. I took advantage of GitLab's advanced features to streamline the process and improve the automation of code implementations. Scanning of Security Vulnerabilities To address security vulnerabilities, I integrated Snyk and OWASP into the CI/CD pipeline. I established automated checks and balances within the CI/CD process, ensuring that each code change went through comprehensive quality and security reviews before its implementation. Results My contributions significantly improved the robustness of Devo's CI/CD pipeline, ensuring that code quality and security were maintained at the highest levels.</p>",
          "images": [],
          "links": [],
          "name": "Integrating quality and safety reviews into the CI/CD pipeline",
          "technologies": [
            "Jira",
            "Kubernetes",
            "Owasp",
            "Snyk",
            "SonarQube",
            "FedRAMP",
            "FIPS",
            "NIST",
            "Jenkins",
            "Gitlab CI/CD"
          ]
        },
        {
          "description": "<p>I was instrumental in developing a comprehensive alert system designed to monitor performance and critical situations in production environments using Prometheus. Recognizing the need for real-time monitoring and rapid response mechanisms, I designed a solution that provided detailed insights into system performance and detected potential problems such as fraud, attacks and other anomalies. To achieve this, I integrated Prometheus into Devo's infrastructure, setting up robust metrics and alerts collection mechanisms. I defined key performance indicators (KPIs) and key thresholds to maintain system health and stability. In addition to setting up the alert system, I developed a comprehensive troubleshooting guide to assist the operations team in diagnosing and resolving problems quickly. The guide ensured that team members had a clear understanding of how to handle different types of alerts, from minor performance degradations to critical system failures. To improve the overall effectiveness of the monitoring system, I also designed protocols to handle critical system situations. My contributions to creating the alert system not only improved the monitoring capabilities of Devo's platform, but also strengthened its security stance by enabling early detection of fraud and attacks.</p>",
          "images": [],
          "links": [],
          "name": "Creating an alert system for monitoring with Prometheus",
          "technologies": [
            "GIT",
            "Ansible",
            "Bash",
            "Python",
            "Kibana",
            "Elastic Stack",
            "Docker",
            "Kubernetes",
            "Grafana",
            "Prometheus"
          ]
        }
      ],
      "short_description": "A cloud-based company that offers real-time security analytics, machine learning and scalable solutions for enterprise data management.",
      "thumbnail": "devo.png"
    },
    {
      "contribution": "<p>At the European Commission, I worked as a software architect on three projects, with a wide range of responsibilities that demonstrated my experience and leadership in software development. Non-functional requirements management and project definition : Using Enterprise Architect, I was responsible for identifying and managing non-functional requirements, ensuring that each project was clearly defined and aligned with organizational objectives. Selection of technology : I was instrumental in selecting appropriate technologies for each project, ensuring that they were appropriate to meet the needs of the project. Definition of Profiles of Team Members : I defined the profiles and roles of the team members, ensuring that the team had the skills and experience needed to succeed. Quality control and testing : I defined quality controls and test protocols, including unit testing using technologies like JUnit or Google Test/Valgrind, depending on the programming language. Software development methodologies : I applied the practices of Test-Based Development (TDD) and Behavioral Development (BDD) to ensure high-quality software development.</p>",
      "full_description": "<p>The European Commission is the executive arm of the European Union, responsible for proposing legislation, implementing decisions, defending EU treaties and managing the EU's daily affairs. Within the European Commission, the Directorate-General for Competition (DG COMP) plays a crucial role. DG COMP is responsible for establishing and implementing competition policy to ensure fair competition within the EU internal market. I worked at DG COMP, contributing to the Commission's efforts to maintain competitive markets and promote economic growth throughout the European Union.</p>",
      "images": [],
      "links": [
        {
          "icon": "",
          "text": "Website of the European Commission, DG COMP",
          "url": "https://competition-policy.ec.europa.eu/index_en"
        }
      ],
      "name": "Comisión Europea",
      "period_time": {
        "current": false,
        "end": "January 2020",
        "start": "June 2017"
      },
      "projects": [
        {
          "description": "<p>The first project involved the definition of two RESTful APIs that implemented the Richardson Level 3 Maturity Model, incorporating HATEOAS. Internal API : The first API was intended to serve the internal staff of the European Commission. External API : The second API served as a platform for external staff. Additionally, the APIs were integrated with an internal secure document storage project via a SOAP interface.</p>",
          "images": ["European_Commission_02.png"],
          "links": [
            {
              "icon": "",
              "text": "Documentation of e-leniency",
              "url": "https://competition-policy.ec.europa.eu/document/download/2fc568de-61ff-4aaf-9c9b-e03e96324ef7_en?filename=eleniency_guidance_access-notification.pdf"
            }
          ],
          "name": "Definition of two RESTful APIs",
          "technologies": [
            "BDD",
            "TDD",
            "SonarQube",
            "Bamboo",
            "JUnit",
            "Jira",
            "CAS",
            "GIT",
            "Maven",
            "Selenium",
            "AngularJS",
            "JUnit",
            "Swagger",
            "MongoDB",
            "Oracle DB",
            "WebLogic 12",
            "Eclipselink",
            "JPA",
            "Spring IoC",
            "Spring Documentation",
            "Spring Data",
            "Spring MVC",
            "Spring Security",
            "Java"
          ]
        },
        {
          "description": "<p>In the second project, I played a crucial role as a software architect, overseeing the development of a sophisticated system for negotiating confidential versions of legal documentation in antitrust proceedings. These groups, composed of internal staff, were verified through the Central Authentication Service (CAS), a system previously implemented under my direction. I designed the architecture of the system that governs the status of each document using the Status design pattern, which allows for reversal of changes, ensuring the integrity and accuracy of legal documents during the negotiation process. Through my leadership and technical experience, I significantly improved the project's ability to provide a secure, reliable and easy-to-use platform for negotiating sensitive legal documents, thereby strengthening the effectiveness of antitrust enforcement actions.</p>",
          "images": [],
          "links": [
            {
              "icon": "",
              "text": "E-confidentiality documentation",
              "url": "https://competition-policy.ec.europa.eu/index/it-tools/econfidentiality_en"
            }
          ],
          "name": "E-Confidentiality",
          "technologies": [
            "WebLogic 12",
            "TDD",
            "Swagger",
            "Spring Security",
            "Spring MVC",
            "Spring IoC",
            "Spring Documentation",
            "Spring Data",
            "SonarQube",
            "Selenium",
            "Oracle DB",
            "MongoDB",
            "Maven",
            "Jira",
            "Java",
            "JUnit",
            "JPA",
            "IntelliJ IDEA",
            "GIT",
            "Enterprise Architect",
            "Eclipselink",
            "Docker",
            "CAS",
            "Bamboo",
            "BDD",
            "Ansible",
            "AngularJS"
          ]
        },
        {
          "description": "<p>The third project, proposed by me, focuses on developing a sophisticated system for semantic indexing of legal documents. The project uses clustering techniques, specifically the K-Means algorithm, applied to the legal document dataset of the antitrust department. Semantic search capability is enhanced by a neural network trained in the dataset of antitrust legal documents, using the TensorFlow framework. This dual service approach not only facilitates high-speed semantic searches, but also ensures robust and scalable indexing of complex legal documents.</p>",
          "images": [],
          "links": [],
          "name": "Semantic index of legal documents",
          "technologies": [
            "gRPC",
            "WebLogic 12",
            "Valgrind",
            "TensorFlow",
            "Swagger",
            "Spring Security",
            "Spring MVC",
            "Spring Documentation",
            "Spring Data",
            "SonarQube",
            "Selenium",
            "Oracle DB",
            "OpenCL",
            "Microservices",
            "Maven",
            "Jira",
            "Java",
            "JUnit",
            "JPA",
            "IntelliJ IDEA",
            "Groovy",
            "Google Test",
            "GIT",
            "Enterprise Architect",
            "Eclipselink",
            "Docker",
            "Cassandra",
            "CUDA",
            "C++",
            "Bamboo",
            "Ansible",
            "AngularJS"
          ]
        },
        {
          "description": "<p>The fourth project involves the development of a renewable energy distribution system within the electricity grid, with the aim of normalizing and stabilizing electricity consumption over time to maximise the use of renewable energies. At the core of the communication system is a Kafka-based messaging cluster, where communication with devices is managed through Avro schemes. This gateway system was developed in Go, using the ModBus communications protocol in its serial and TCP versions, with TCP communications secured via a VPN. My practical approach and technical expertise were essential to tackling the challenges of renewable energy distribution, and my contribution to harnessing advanced technologies and developing robust communication protocols underlines my significant role in this innovative project aimed at improving the stability and efficiency of the use of renewable energy within the electricity grid.</p>",
          "images": [],
          "links": [],
          "name": "Development of a renewable energy distribution system",
          "technologies": [
            "Groovy",
            "Jira",
            "Kibana",
            "Elastic Search",
            "Ansible",
            "Avro Schemas",
            "Kafka",
            "IoTHub",
            "Azure",
            "GCP",
            "Kubernetes",
            "Docker",
            "Make",
            "Python",
            "Modbus",
            "RaspberryPI",
            "BalenaIO",
            "Unit Test",
            "Go"
          ]
        }
      ],
      "short_description": "The European Commission is the executive arm of the European Union, responsible for proposing legislation, implementing decisions and managing daily affairs.",
      "thumbnail": "European_Commission_01.png"
    },
    {
      "contribution": "<p>At Panel Systems, I worked as a functional analyst on three projects. My responsibilities as a functional analyst included: Analysis of non-functional requirements and decision-making on the exact implementation of the solution (Redmine) Creating sub-tasks with less granularity to achieve objectives (Redmine) Estimated time (Redmine) Definition and implementation of the project structure in the specified technologies Definition of the coverage and quality of unit tests (JUnit, Google Test, Valgrind) Implementation of IC/CD systems (Jenkins) Use of SCRUM as a development methodology Application of TDD and BDD in software development Teaching training sessions on TDD, BDD, Neural Networks, Clean Code and more</p>",
      "full_description": "<p>Panel Sistemas is a leading technology solutions company, specializing in software development, consulting and IT services. Founded in Spain, it serves various industries with leading clients such as Telefónica, BBVA, Santander, Repsol and El Corte Inglés. Services offered Software development: Tailored software solutions. Consulting: IT strategy and optimization.</p>",
      "images": [],
      "links": [
        {
          "icon": "",
          "text": "Website of the Systems Panel",
          "url": "https://www.panel.es/"
        }
      ],
      "name": "Panel Sistemas",
      "period_time": {
        "current": false,
        "end": "June 2017",
        "start": "In September 2015"
      },
      "projects": [
        {
          "description": "<p>This project successfully replaced the outdated IATA standard, based on flat text and prone to human error due to its reliance on the position of the text chain, with a more modern, readable and error-resistant format based on XML/JSON. To achieve this, I defined an analyzer that translated messages from the old format to either of the two modern standards through a Restful API that met the Richardson Level 3 maturity model.</p>",
          "images": ["iata.png"],
          "links": [],
          "name": "Modernisation of maritime and air transport messaging: replacement of IATA by XML/JSON",
          "technologies": [
            "Ansible",
            "Docker",
            "IntelliJ IDEA",
            "Redmine",
            "Jenkins",
            "GIT",
            "Maven",
            "Selenium",
            "Hadoop",
            "Phonegap",
            "AWS",
            "GWT",
            "Primefaces",
            "JSF",
            "JUnit",
            "RabbitMQ",
            "MongoDB",
            "Wildfly/JBoss",
            "Hibernate",
            "JPA",
            "Spring Documentation",
            "Spring Data",
            "Spring MVC",
            "Spring Security",
            "Java"
          ]
        },
        {
          "description": "These terminals were stored in a non-relational MongoDB database, which for obvious reasons were several clusters, with load balancing and replicated fragments. This data consumption was generated for one year using the JCPOA system and this data was then maintained at a time-based level called the JCPOA, and this data was then maintained at a time-based level called the JCPOA.",
          "images": ["iberdrola.svg", "siemens.png"],
          "links": [],
          "name": "Intelligent terminal management of Iberdrola with Siemens",
          "technologies": [
            "Spring IOT",
            "Spring Documentation",
            "Spring Data",
            "Spring MVC",
            "Spring Security",
            "SNMP",
            "JNLP",
            "Kubernetes",
            "Ansible",
            "Docker",
            "IntelliJ IDEA",
            "Jira",
            "Jenkins",
            "GIT",
            "Maven",
            "Hadoop",
            "Primefaces",
            "JSF",
            "JUnit",
            "MongoDB",
            "Apache Tomcat",
            "Hibernate",
            "JPA",
            "RabbitMQ",
            "Java",
            "Microservices",
            "gRPC",
            "Boost",
            "cLion",
            "Valgrind",
            "Google Test",
            "C++"
          ]
        },
        {
          "description": "<p>The system identified the status of the user based on various sensors distributed throughout their home, including presence sensors, door opening sensors, and personal fall sensors. This data was collected to provide detailed information about the user's activities, which was not only stored and accessible for consultation, but was also capable of generating alarms based on the individual's typical behavior patterns.</p>",
          "images": [],
          "links": [],
          "name": "Monitoring and care system for persons with disabilities or the elderly for Securitas Direct",
          "technologies": [
            "Kubernetes",
            "Ansible",
            "Docker",
            "IntelliJ IDEA",
            "Confluence",
            "Jira",
            "Jenkins",
            "GIT",
            "Maven",
            "Jasmine",
            "Selenium",
            "Hadoop",
            "Typescript",
            "Ionic",
            "JUnit",
            "Oracle DB",
            "Apache Tomcat",
            "Hibernate",
            "JPA",
            "RabbitMQ",
            "Spring Batch",
            "Spring IoC",
            "Spring Documentation",
            "Spring Data",
            "Spring MVC",
            "Spring Security",
            "AWS",
            "Java",
            "Microservices",
            "gRPC",
            "Boost",
            "cLion",
            "Valgrind",
            "Google Test",
            "C++"
          ]
        }
      ],
      "short_description": "Panel Systems is a technology solutions company offering software, consulting and development services to various industries.",
      "thumbnail": "panel_sistemas.png"
    },
    {
      "contribution": "<p>I have extensive experience working as a remote senior programmer on three important projects. In this role, I was entrusted with a variety of critical responsibilities that required both technical expertise and strong communication skills. One of my main duties was to attend meetings with the product owner to define the detailed requirements of the project. This involved a thorough analysis of the project objectives and break them down into specific and processable tasks. To facilitate fluid communication and collaboration, I translated and interpreted the requirements into Chinese. This linguistic skill was crucial to overcome communication gaps and ensure that all team members, regardless of their location, had a clear and accurate understanding of the project requirements. I used the SCRUM methodology to ensure that all tasks were organized and managed effectively throughout the project lifecycle. This involved creating detailed plans, setting realistic timelines, and continually monitoring progress to ensure that project milestones were met. Overall, my experience as a senior remote programmer has provided me with a diverse skill set and a deep understanding of effective project management in a remote and global work environment. My ability to define detailed requirements, coordinate with international teams, innovate to improve productivity and manage projects using SCRUM has allowed me to contribute significantly to the success of the projects I have been involved in.</p>",
      "full_description": "<p>Grupo PRISA, formally known as Promotora de Informaciones, S.A., is a prominent Spanish media conglomerate with significant influence in the Spanish-speaking world. Founded in 1972 by Jesús de Polanco, PRISA has grown to become one of the largest media companies in Spain and Latin America, encompassing a wide range of media, including newspapers, radio stations, television channels and educational publications. Key aspects of PRISA Group include: Newspapers: PRISA's flagship newspaper is The country , one of Spain's most widely read and respected newspapers. Launched in 1976 during Spain's democratic transition, The country It quickly became a symbol of the new democratic era, offering high-quality journalism and a progressive editorial stance. The newspaper covers a wide range of topics, from national and international news to culture, economics and sports. It has a substantial audience and is known for its complete coverage of news and tertulia programs that address current affairs, politics and social issues. Television: PRISA has also ventured into television, with its channel CNN+ Having been a significant player in the Spanish news market until its closure in 2010, despite this, PRISA continues to have a presence in the television sector through various partnerships and content production. It offers a wide range of textbooks, digital content and educational resources for students and teachers, making significant contributions to education in the Spanish-speaking world. The company has invested heavily in digital platforms, mobile applications and online content to reach a wider audience and remain relevant in the digital age. The company's content is consumed by millions of people worldwide, making it a significant cultural and information bridge between Spain, Latin America and the rest of the world.</p>",
      "images": [],
      "links": [
        {
          "icon": "",
          "text": "The website of Grupo Prisa",
          "url": "https://www.prisa.com/es"
        }
      ],
      "name": "Grupo Prisa",
      "period_time": {
        "current": false,
        "end": "May 2015",
        "start": "March 2012"
      },
      "projects": [
        {
          "description": "<p>In addition, the application was equipped with functionality to track and send users' progress to the server, facilitating effective monitoring and evaluation of their learning journey. A key feature of the application was its ability to manage educational packages that met the SCORM (Shared Content Object Reference Model) standard, which is widely used in the field of e-learning to create and deliver interactive and adaptive learning content. This dual compatibility ensured that users could access a wide range of old educational content, both modern and old, thus improving the usefulness and appeal of the application in various educational contexts.</p>",
          "images": [],
          "links": [],
          "name": "Application of the educational package visor",
          "technologies": [
            "Confluence",
            "GIT",
            "Jira",
            "jQuery",
            "Bootstrap",
            "JavaScript",
            "HTML",
            "SCORM",
            "Dagger",
            "Objective-C",
            "XCode",
            "Android Studio",
            "Java"
          ]
        },
        {
          "description": "<p>In an effort to save costs associated with migrating Flash to HTML5 under the SCORM standard, the decision was made to develop a translation tool from Flash to HTML5. This tool facilitated the conversion of educational content from Flash to HTML5, ensuring compatibility with the SCORM standard. The project not only achieved cost savings and improved efficiency, but also provided a robust framework for future updates and improvements, ensuring the longevity and adaptability of educational content.</p>",
          "images": [],
          "links": [],
          "name": "Project for standardisation of education packages",
          "technologies": [
            "Valgrind",
            "NginX",
            "Bash",
            "Xen",
            "KVM",
            "QEmu",
            "Confluence",
            "GIT",
            "Jira",
            "jQuery",
            "SCORM",
            "Bootstrap",
            "AngularJS",
            "JavaScript",
            "HTML",
            "Flash",
            "Linux",
            "C++"
          ]
        },
        {
          "description": "<p>This platform enabled users to manage various educational tasks, including managing students, managing educational packages and analyzing their results. In addition, the platform had a high-resolution audio and video communication center via IP, improving real-time interactions between educators and students.</p>",
          "images": [],
          "links": [],
          "name": "Project of educational platform",
          "technologies": [
            "Confluence",
            "GIT",
            "Jira",
            "Microsoft SQL Server",
            "Windows Server",
            "IIS",
            ".NET",
            "C#"
          ]
        }
      ],
      "short_description": "Grupo PRISA is a Spanish media conglomerate, known for its influential newspapers, radio stations and educational publications.",
      "thumbnail": "prisa.png"
    },
    {
      "contribution": "<p>This application served as a real-time interactive interface with television content, updated through inaudible markers embedded in the audio. The audio was intercepted by the application, using a custom solution developed in the Android NDK to ensure high performance and low battery consumption.</p>",
      "full_description": "<p>This platform enabled users to manage various educational tasks, including managing students, managing educational packages and analyzing their results. In addition, the platform had a high-resolution audio and video communication center via IP, improving real-time interactions between educators and students.</p>",
      "images": [],
      "links": [
        {
          "icon": "",
          "text": "The website of Intelygenz",
          "url": "https://intelygenz.com/"
        }
      ],
      "name": "Intelygenz",
      "period_time": {
        "current": false,
        "end": "January 2012",
        "start": "January 2010"
      },
      "projects": [
        {
          "description": "<p>This application served as a real-time interactive interface with television content, dynamically updated using inaudible markers embedded in audio. This innovative approach allowed the application to seamlessly interact with the television broadcast, providing users with an enhanced and engaging viewing experience.</p>",
          "images": ["intelygenz_01.jpeg"],
          "links": [
            {
              "icon": "",
              "text": "Documentation of the antenna 3 TV application",
              "url": "https://www.atresmediacorporacion.com/a3document/2012/05/24/DOCUMENTS/00012/00012.pdf"
            }
          ],
          "name": "Project Antenna 3 Television",
          "technologies": [
            "Confluence",
            "GIT",
            "Jira",
            "Android NDK",
            "Android Studio",
            "Java"
          ]
        },
        {
          "description": "<p>In addition, the document manager integrated BBVA's workflow and business logic, enabling smooth interaction with other banking entities. This implementation not only streamlined document management processes, but also ensured that the bank's operations were aligned with industry standards and best practices, thus improving efficiency and collaboration between different departments and external partners.</p>",
          "images": ["bbva.jpg"],
          "links": [],
          "name": "Project document manager for BBVA",
          "technologies": [
            "Confluence",
            "GIT",
            "Jira",
            "jQuery",
            "Bootstrap",
            "JavaScript",
            "HTML",
            "Cassandra",
            "Microsoft SQL Server",
            "Windows Server",
            "IIS",
            ".NET",
            "C#"
          ]
        },
        {
          "description": "<p>This project was integrated with the NACAR environment, a platform designed to improve the functionality and user experience of banking applications. This library was designed to improve user interaction by providing intuitive and efficient ways to perform various tasks.</p>",
          "images": ["bbva.jpg"],
          "links": [],
          "name": "Collaborative Front project",
          "technologies": [
            "Eclipse",
            "GIT",
            "Confluence",
            "Jira",
            "GIT",
            "Maven",
            "JSF",
            "JUnit",
            "Oracle DB",
            "Websphere",
            "Hibernate",
            "JPA",
            "Spring Documentation",
            "Spring Data",
            "Spring MVC",
            "Spring Security",
            "Java"
          ]
        }
      ],
      "short_description": "Intelygenz is a technology company specialising in artificial intelligence, machine learning and tailor-made software solutions for various industries.",
      "thumbnail": "intelygenz.png"
    },
    {
      "contribution": "<p>My role as a researcher at the university was within the TIFyC research group, where I had a range of responsibilities focused on advancing the field of technology and artificial intelligence. One of my main tasks was to conduct comprehensive research on the state of the art in various areas, including accessibility issues, AI algorithms, artificial vision and biometric systems. In addition to my research duties, I actively participated in collaborations with research groups from different universities. Another key aspect of my role was preparing detailed reports on our research findings. In addition, I participated in the study and application for State aid and grants for research and development (R&D) projects, which required a thorough understanding of the financing landscape and the ability to develop compelling proposals that demonstrated the importance and potential impact of our research. My teaching role allowed me to share my passion for AI and artificial vision with the next generation of researchers and professionals, while remaining committed to the academic community.</p>",
      "full_description": "<p>The University of Alcalá de Henares, commonly known as the University of Alcalá, is a renowned public university located in Alcalá de Henares, a historic city near Madrid, Spain. Founded in 1499 by Cardinal Cisneros, it is one of the oldest universities in Spain and has a rich heritage that combines tradition with modernity. The University of Alcalá is celebrated for its commitment to academic excellence and innovation. It offers a wide range of undergraduate, postgraduate and doctoral programs in various fields of study, including humanities, social sciences, natural sciences, engineering, health sciences and law. The university is particularly known for its solid programs in literature, linguistics and Spanish language studies, attracting students and academics from all over the world. One of the most notable features of the university is its historic campus, which is a UNESCO World Heritage site. The campus includes impressive examples of Spanish Renaissance architecture, such as the College of San Ildefonso, the main building of the university, which has a beautiful courtyard and a historic chapel. In addition to its historic campus, the University of Alcalá has modern facilities equipped with the latest technology to support cutting-edge research and innovative teaching methods. The university's libraries, laboratories and research centers provide students and professors with the resources they need to pursue their academic and professional goals. The vibrant student life of the university includes numerous cultural, social and sporting activities, providing students with opportunities to interact with the wider community and develop their personal and professional skills.</p>",
      "images": [],
      "links": [
        {
          "icon": "",
          "text": "Website of the University of Alcalá",
          "url": "https://uah.es/"
        }
      ],
      "name": "UAH",
      "period_time": {
        "current": false,
        "end": "January 2009",
        "start": "January 2006"
      },
      "projects": [
        {
          "description": "<p>One of the significant projects carried out by our research group focused on researching innovative devices designed to improve interaction for individuals with visual, auditory or motor disabilities. The main objective of this research was to develop and refine technologies that could facilitate more intuitive and accessible interactions with various types of systems, including desktop computers, laptops and mobile devices. This included developing specialized input devices, adaptive software solutions, and advanced user interface designs that specifically tailored to the needs of users with visual, auditory, and motor disabilities. By integrating feedback from real users, our research group was able to make significant strides in creating devices and applications that not only met accessibility standards, but also improved the overall user experience for people with disabilities.</p>",
          "images": ["tifyc.jpg"],
          "links": [],
          "name": "Project of the research group",
          "technologies": [
            "Mono",
            ".NET",
            "C#",
            "SVN",
            "Arduino",
            "PIC",
            "Qt",
            "Anjuta",
            "C++",
            "Linux",
            "Android",
            "Android Studio",
            "Java"
          ]
        },
        {
          "description": "<p>The second project I worked on involved developing a standardized communication system for biometric devices. This RPC system ensured that communication between devices remained transparent regardless of the programming language or operating system used. The project required careful consideration of interoperability issues, as biometric devices often come with proprietary communication protocols and diverse technical specifications. By implementing a standardized RPC system, we were able to abstract the underlying differences and create a unified communication protocol. In addition, the communication system was designed to be highly robust and secure, given the sensitive nature of biometric data. This project not only improved the compatibility of devices but also paved the way for future advances in biometric technology, allowing manufacturers to focus on innovation without worrying about communication barriers.</p>",
          "images": [],
          "links": [],
          "name": "Communication system for biometric devices",
          "technologies": [
            "Mono",
            ".NET",
            "C#",
            "SVN",
            "Anjuta",
            "C++",
            "Linux",
            "Java"
          ]
        },
        {
          "description": "<p>The third project involved the continuous creation and maintenance of the research group's website using the Joomla Content Management System (CMS). This project required not only the initial development of an easy-to-use and visually appealing website, but also the continuous updating and improvement of its features and content to meet the evolving needs of the research group. The website served as a central hub for the research group's activities, providing access to future publications, project updates and events. Taking advantage of Joomla's robust framework, I ensured that the website was both secure and scalable, capable of handling a growing volume of content and user interactions.</p>",
          "images": ["tifyc.jpg"],
          "links": [],
          "name": "Project website of the research group",
          "technologies": [
            "Mono",
            ".NET",
            "C#",
            "SVN",
            "Anjuta",
            "C++",
            "Linux",
            "Java"
          ]
        },
        {
          "description": "<p>I also organized and conducted specialized seminars focused on robotics, sharing advanced knowledge and the latest developments in the field with my colleagues and students. In addition, I served as an assistant professor, where I taught subjects such as Artificial Intelligence and Artificial Vision. In this role, I was responsible for preparing and dictating lectures, attending course design and providing guidance to students on complex topics related to AI technologies and computer vision. I competed in the maze-resolution mode, where I applied my experience in robotics and AI to design and program robots capable of navigating and solving maze-resolving.</p>",
          "images": ["hispabot.jpeg"],
          "links": [],
          "name": "Contributions to the research group",
          "technologies": [
            "Python",
            "Java",
            "Octave",
            "Mathlab",
            "PIC",
            "Arduino",
            "C++",
            "C"
          ]
        }
      ],
      "short_description": "The University of Alcalá de Henares is a prestigious Spanish institution known for its rich history and various academic programs.",
      "thumbnail": "uah.svg"
    },
    {
      "contribution": "<p>During my early college years, in order to pay for my studies, I worked as a junior web programmer using CMS at Knowcentury.</p>",
      "full_description": "Small company dedicated to creating websites",
      "images": [],
      "links": [],
      "name": "Knowcentury",
      "period_time": {
        "current": false,
        "end": "July 2005",
        "start": "January 2005"
      },
      "projects": [
        {
          "description": "<p>Implementation of web pages using CMS such as Joomla, Drupal and Moodle.</p>",
          "images": [],
          "links": [],
          "name": "Development of websites",
          "technologies": ["HTML", "MySQL", "JavaScript", "PHP", "Joomla"]
        }
      ],
      "short_description": "Small company dedicated to creating websites",
      "thumbnail": "knowcentury.png"
    },
    {
      "contribution": "<p>During this period, my main responsibility was to conduct extensive research into the use of the IBM System Z/390s mainframe for system virtualization. The goal was to enable the use of remote systems by creating virtualized environments on the IBM mainframe. These virtual systems were to operate under the Suse Linux Enterprise Edition operating system, ensuring a robust and secure platform for various applications and services. My role required a comprehensive understanding of the architecture and capabilities of the IBM System Z/390s. This involved configuring and optimizing the mainframe to support multiple virtual machines, each running its own instance of the Suse Linux Enterprise Edition. The project aimed to leverage the power and reliability of the IBM System Z/390s to provide scalable and secure virtualized solutions for enterprise applications.</p>",
      "full_description": "<p>IBM, or International Business Machines Corporation, is a world-renowned technology company with a rich history spanning more than a century. Founded in 1911 and headquartered in Armonk, New York, IBM has been constantly at the forefront of technological innovation, influencing numerous sectors with its pioneering solutions. Today, IBM is a leader in cloud computing, artificial intelligence (AI) and enterprise hardware, offering a complete suite of products and services that cater to businesses of all sizes. One of IBM's most significant contributions to technology is its development of powerful AI systems, particularly the IBM Watson platform. Watson is designed to leverage natural language processing and machine learning to analyze large amounts of data, providing information and enabling automation in various industries, including health, finance and customer service. IBM Watson's capabilities in data analysis and predictive analytics help organizations make more informed decisions, improve operational efficiency, and drive innovation. In addition to AI, IBM has made substantial advances in cloud computing with its IBM Cloud platform. This robust platform offers a wide range of cloud services, including infrastructure as a service (IaaS), platform as a service (PaaS), and software as a service (SaaS). IBM Cloud is designed to support both public and private cloud environments, enabling companies to deploy and manage applications with greater flexibility and security. IBM's hardware solutions have also played a key role in the company's success. The IBM Z series of mainframes, for example, are known for their reliability, security, and performance, particularly in industries that require robust data processing capabilities, such as banking and finance. Another key area of IBM's expertise is its commitment to research and development (R&D).</p>",
      "images": [],
      "links": [],
      "name": "IBM",
      "period_time": {
        "current": false,
        "end": "December 2004",
        "start": "In September 2003"
      },
      "projects": [
        {
          "description": "<p>Implementation of web pages using CMS such as Joomla, Drupal and Moodle.</p>",
          "images": ["ibm_system_z.jpg", "kvm.png", "suse.png"],
          "links": [],
          "name": "Development of websites",
          "technologies": ["HTML", "MySQL", "JavaScript", "PHP", "Joomla"]
        }
      ],
      "short_description": "IBM, a global technology company, specializes in cloud computing, AI and hardware, providing innovative solutions for businesses around the world.",
      "thumbnail": "ibm.svg"
    }
  ]
}
