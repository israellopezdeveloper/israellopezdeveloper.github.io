{
  "profile": {
    "greeting": "Hello, I'm Israel, a hardened senior developer traveling the world.",
    "profile_image": "israel.png",
    "name": "Israel López",
    "title": "Senior Software Engineer",
    "summary": "<p>My backpack is full of code and I want to keep learning. Programming is my superpower!</p>\n<p>I've been bitten by the programming worm since I was 13 and I couldn't stop anywhere in the world with my laptop under my arm!</p>\n<p>I consider myself a restless mind because of my insatiable desire to learn, innovate and overcome new intellectual challenges.</p>\n<p>I'm lucky that programming is not only my job, it's also my passion, and if there's anything that characterizes me, it's my insistence on finding the optimal solution to the project, because yes, I'm proud to deliver clean, efficient code.</p>\n<p>If we connect, are you ready to embark on a new technological adventure with me?</p>",
    "links": [
      {
        "text": "@israellopezdeveloper",
        "url": "https://github.com/israellopezdeveloper",
        "icon": ""
      },
      {
        "text": "israel.lopez.developer@gmail.com",
        "url": "mailto:israel.lopez.developer@gmail.com",
        "icon": "󰇮"
      },
      {
        "text": "https://www.linkedin.com/in/israellopezmaiz/",
        "url": "https://www.linkedin.com/in/israellopezmaiz/",
        "icon": "󰌻"
      },
      {
        "text": "+34 648 13 66 40",
        "url": "tel:+34648136640",
        "icon": ""
      }
    ],
    "hobbies": "<p> climbing,  snowboarding,  traveling,  diving,  mathematics (especially linear algebra and statistics),  Artificial intelligence.</p>",
    "bio": [
      {
        "dates": "1983",
        "text": "I was born in Madrid, Spain"
      },
      {
        "dates": "2007 and 2007",
        "text": "Completed his bachelor's degree in Computer Science at the University of Alcalá de Henares"
      },
      {
        "dates": "2009 and 2009",
        "text": "He completed his Master's degree in Artificial Intelligence in Information and Communication Technologies at the University of Alcalá de Henares."
      },
      {
        "dates": "2004 to the present",
        "text": "Working as an employee"
      }
    ]
  },
  "works": [
    {
      "name": "Datura AI",
      "short_description": "Datura AI is a startup specializing in decentralized technologies for networks such as Bittensor. Its mission is to build solutions that surpass centralized systems, offering easy-to-use tools and high performance.<strong>Celium</strong>, a platform for instantaneous deployment of AI models in containers, enabling pod editing, deployment templates, and rapid execution of models such as Stable Diffusion or Whisper.",
      "thumbnail": "daturaai.png",
      "period_time": {
        "start": "March 2025",
        "end": "",
        "current": true
      },
      "full_description": "<p><strong>Date and time</strong>is a company specializing in the development of technologies for the distribution and execution of AI models in decentralized networks and distributed environments. Its goal is to eliminate the limitations of centralized systems, offering tools that allow AI models to be deployed in a secure, fast and scalable manner, both in the cloud and on remote devices.</p>\n<p>Its main product, <strong>Celium</strong>, is a platform for orchestrating and managing AI models in containers.</p>\n<ul>\n<li>Immediately deploy models in distributed environments or on the edge.</li>\n<li>Edit pods and adjust resources dynamically.</li>\n<li>Use templates optimized for models such as Stable Diffusion, Whisper, LLaMA or Mistral.</li>\n<li>Monitor and optimize performance in real time.</li>\n<li>Integrate with decentralized ecosystems like Bittensor.</li>\n</ul>",
      "contribution": "<ul>\n<li>Optimization of the deployment cycle of models in distributed environments, reducing production time.</li>\n<li>Implementation of modules in Python and Rust for model management, monitoring and fault recovery.</li>\n<li>C code integration for high performance critical operations.</li>\n<li>Automation of deployment pipelines with Docker and Kubernetes.</li>\n<li>Optimization of GPU and CPU usage to maximize energy efficiency.</li>\n<li>Cooperation with the product team to define scalability and cost reduction strategies.</li>\n</ul>",
      "links": [
        {
          "text": "Web site",
          "url": "https://www.datura.ai"
        }
      ],
      "projects": [
        {
          "name": "Platform for the orchestration and distribution of AI models in distributed environments",
          "description": "<p>Celium is a platform developed by <strong>Date and time</strong>It aims to facilitate the execution of complex models, such as Stable Diffusion, Whisper, LLaMA or Mistral, even in environments with limited resources, ensuring high availability, scalability and performance.</p>\n<p>The platform allows users to:</p>\n<ul>\n<li>Instantly deploy models in containers on local infrastructure, in the cloud or on the edge.</li>\n<li>Edit pods and reallocate resources (CPU, GPU, memory) dynamically to adapt to demand.</li>\n<li>Use deployment templates optimized for specific models.</li>\n<li>Monitor performance metrics and resource use in real time.</li>\n<li>Automate the updating and distribution of models at hundreds of remote nodes.</li>\n<li>Integrate the platform with decentralized ecosystems such as Bittensor to increase interoperability.</li>\n</ul>\n<p>Celium uses a modular architecture based on containers and orchestrators, optimized to reduce latency and resource consumption. It employs intelligent load balancing, distributed data management, and advanced process affinity techniques to maximize energy efficiency and the performance of available hardware.</p>\n",
          "technologies": [
            "Python",
            "Rust",
            "C",
            "Docker",
            "Kubernetes",
            "Helm",
            "Git",
            "GitHub Actions",
            "GPU Computing",
            "CUDA",
            "Tech",
            "Bittensor",
            "Prometheus"
          ],
          "links": [
            {
              "text": "Portal of Celium",
              "url": "https://lium.io/"
            }
          ],
          "images": []
        }
      ],
      "images": []
    },
    {
      "name": "Indra",
      "short_description": "Indra is a leading Spanish multinational in consulting and technology, with presence in more than 140 countries. It offers innovative solutions for sectors such as Defence, Transport, Energy, Security and Digital Transformation. In the field of Defence, it develops strategic and mission-critical systems that strengthen the technological autonomy and interoperability of the armed forces of Europe and NATO allies.",
      "thumbnail": "indra.png",
      "period_time": {
        "start": "April 2024",
        "end": "February 2025",
        "current": false
      },
      "full_description": "<p>Indra is one of the leading global consulting and technology companies, a leader in integrated solutions for the defence, transport, energy, security and digital transformation sectors. With a strong international presence, Indra develops strategic systems and technologies for customers in Europe, America, Asia and Africa.</p>\n<p>In the field of Defence, Indra is leading the development of the first next-generation mission system for military vehicles from Europe and NATO countries, a pioneering project that seeks to provide the armed forces with an open, modular and scalable platform that integrates sensors, communication systems, AI capabilities and GIS components to optimize decision-making in complex operational environments.</p>\n<p>I worked on this project as a Senior Software Engineer, contributing to the definition, development and integration of critical components into a technological ecosystem that combined Java, Node.js, Python, Augmented Information Recovery (RAG) systems and GIS.</p>",
      "contribution": "<p>In Indra I participated in the following key areas:</p>\n<ul>\n<li><strong>Backend design and implementation</strong>in Java and Node.js with Clean Architecture principles to achieve sustainability and scalability.</li>\n<li><strong>Integration of an RAG system</strong>for contextual recovery of operational intelligence: heterogeneous intake, embeddings and semantic search.</li>\n<li><strong>GIS capabilities</strong>for geospatial analysis, tactical visualization and real-time route/deployment optimization.</li>\n<li><strong>Definition of API and interfaces</strong>to interact with NATO systems, complying with safe standards and protocols.</li>\n<li><strong>Agile (SCRUM) and management in Jira</strong>, prioritizing critical functionalities and coordinating dependencies.</li>\n<li><strong>CI/CD with GitLab</strong>and deployments in <strong>Cocktails</strong>; observability with Prometheus and Grafana.</li>\n<li><strong>Optimization of performance and resilience</strong>: load testing, failure tolerance and simulation of hostile environments.</li>\n</ul>",
      "links": [],
      "projects": [
        {
          "name": "New generation mission system for military vehicles",
          "description": "<p>Strategic project developed by Indra within the framework of the European Defence Fund to create the <strong>first new generation mission system for military vehicles from Europe and NATO countries</strong>. The system integrates AI, GIS and sensor management capabilities to provide the armed forces with a tactical advantage in complex operational environments. </p>\n<p>The architecture is open, modular and scalable, enabling interoperability between allied armies and the rapid integration of new technological components.<strong>RAG system</strong>for contextual information retrieval, real-time geospatial analysis, and secure communication modules for the transmission of critical data. </p>\n<h3>The responsibilities</h3>\n<ul class=\"responsibilities\">\n<li>Design and implementation of backend microservices in Java and Node.js under the principles of Clean Architecture.</li>\n<li>Development and integration of an RAG system for semantic search and contextualization of operational data.</li>\n<li>Implementation of GIS functionalities for geospatial analysis and tactical visualization on interactive maps.</li>\n<li>Definition of secure APIs and protocols to interoperate with other NATO systems.</li>\n<li>Automation of CI/CD pipelines in GitLab with deployments in Kubernetes.</li>\n<li>Performance optimization, load testing and fault tolerance validation.</li>\n</ul>",
          "technologies": [
            "Java",
            "Spring Boot",
            "Spring Data",
            "Spring Security",
            "Node.js",
            "Express",
            "Python",
            "FastAPI",
            "RAG",
            "Vector DB",
            "Embeddings",
            "PostgreSQL",
            "MongoDB",
            "GIS",
            "PostGIS",
            "OpenLayers",
            "Docker",
            "Kubernetes",
            "Helm",
            "GitHub Actions",
            "Jira",
            "Prometheus",
            "Grafana"
          ],
          "links": [
            {
              "text": "Indra's participation in the European Defence Fund",
              "url": "https://www.indracompany.com/es/noticia/indra-lidera-participacion-espanola-proyectos-fondo-europeo-defensa-entra-formar-12"
            }
          ],
          "images": []
        }
      ],
      "images": []
    },
    {
      "name": "Devo",
      "short_description": "A cloud-based company that offers real-time security analytics, machine learning and scalable solutions for enterprise data management.",
      "thumbnail": "devo.png",
      "period_time": {
        "start": "March 2020",
        "end": "March 2024",
        "current": false
      },
      "full_description": "<p>Devo is a leading enterprise in cloud-based registry and native security analytics, dedicated to providing real-time insights and advanced analytics for enterprise data. Its robust platform enables organizations to detect, analyze, and respond efficiently to security threats, leveraging the power of machine learning and a highly scalable architecture. Devo's solutions are designed to handle large volumes of data, ensuring that enterprises can maintain high levels of performance and security. Serving a wide range of industries, including finance and telecommunications, Devo improves cybersecurity measures and optimizes data management practices, helping enterprises stay ahead of evolving threats and regulatory requirements. With a commitment to innovation and excellence, Devo is at the forefront of transforming how enterprises approach data security and analytics.</p>",
      "contribution": "<p>At Devo, I played a crucial role in the data intake team, focusing specifically on the load balancer. Given the sensitivity of the data and its importance for diagnosing potential attacks, the service had to be both reliable and fast. Under my experience, the system was able to handle an impressive volume of intake of approximately 60TB per day. In addition, I contributed significantly to Devo's efforts to adapt to the standards needed for integration with U.S. federal systems, achieving FedRAMP certification. I also participated in the creation of a multi-regional and multicloud backup system, ensuring the redundancy and reliability of data in diverse environments.</p>",
      "links": [
        {
          "text": "Web site of Devo",
          "url": "https://www.devo.com/es/"
        }
      ],
      "projects": [
        {
          "name": "Improvement of the existing load balancer",
          "description": "<p>I contributed significantly to improving the performance of Devo's load balancer by implementing advanced strategies that improved fault tolerance and optimized monitoring of data entry services. I meticulously analyzed system requirements and identified key areas for improvement, ensuring that the load balancer could handle variable traffic levels more efficiently. My efforts to improve fault tolerance mechanisms helped the system recover quickly from unexpected failures, maintaining high availability and reliability.</p><p>I also developed methods to balance customer-based load, which facilitated more compact data queries. By ensuring that data is not mixed unnecessarily at all nodes, streamlining the data recovery process, making it faster and more efficient. This customer-specific load balancing approach not only improved query performance but also reduced system overload. My contributions led to a more robust and responsive load balancing system, significantly improving performance and user experience at Devo.</p>",
          "technologies": [
            "Node.js",
            "C",
            "C++",
            "FIPS",
            "FedRAMP",
            "SonarQube",
            "Snyk",
            "Owasp",
            "Jenkins",
            "Gitlab CI/CD",
            "Kubernetes",
            "GIT",
            "Jira",
            "TDD",
            "BDD"
          ],
          "links": [
            {
              "text": "Documentation of the load balancer",
              "url": "https://docs.devo.com/space/latest/94653692/Event+load+balancers"
            }
          ],
          "images": []
        },
        {
          "name": "Creating a multicloud backup system",
          "description": "<p>I led the development of a state-of-the-art multicloud backup system from scratch, a crucial breakthrough for Devo's redundancy and disaster recovery capabilities. This system was designed to store customer records in multiple regions and environments in the cloud, ensuring maximum protection and availability of data. One of the key features of this system was its ability to configure real-time storage types, allowing fluid adjustments to cloud storage configurations based on real-time needs and criteria.</p><p>I implemented sophisticated data transition criteria, which automated the movement of data between different types of storage based on usage patterns and retention policies. This feature ensured that data was always stored in the most cost-effective and efficient way, without compromising accessibility or performance.</p><p>In addition to this, my system included robust node recovery mechanisms, allowing for quick service restoration in the event of a node failure. This significantly reduced downtime and maintained the integrity and availability of critical data. To further improve system efficiency, I developed advanced data compression methods for data that were near the end of their useful life, optimizing storage usage and reducing overload.</p><p>My contributions to this multicloud backup system not only strengthened Devo's data management capabilities but also ensured compliance with strict security and data retention regulations. This project highlighted my experience in creating resilient, scalable, and highly efficient data storage solutions, reinforcing Devo's commitment to excellence in security and data analytics.</p>",
          "technologies": [
            "Java",
            "AWS",
            "GCP",
            "FIPS",
            "FedRAMP",
            "SonarQube",
            "Snyk",
            "Owasp",
            "Jenkins",
            "Gitlab CI/CD",
            "Kubernetes",
            "GIT",
            "Jira",
            "TDD",
            "BDD"
          ],
          "links": [],
          "images": []
        },
        {
          "name": "Integrating quality and safety reviews into the CI/CD pipeline",
          "description": "<p>I played a key role in integrating comprehensive quality and safety reviews into Devo's CI/CD pipeline. This initiative was crucial in elevating the development process to meet strict industry standards, including NIST, FIPS and FedRAMP.</p><p><b>Integration of the Jenkins Pipeline</b></p><p>Initially, I focused on incorporating SonarQube into the Jenkins pipeline for continuous code quality analysis. I configured SonarQube to perform static code analysis, which allowed the team to detect code odors, errors, and potential vulnerabilities early in the development cycle.</p><p><b>Transition to GitLab CI/CD</b></p><p>After the success with Jenkins, I made the transition from the pipeline to GitLab CI/CD. I took advantage of GitLab's advanced features to streamline the process and improve the automation of code implementations. This change facilitated better collaboration and efficiency throughout the development team.</p><p><b>Scanning of Security Vulnerabilities</b></p><p>To address security vulnerabilities, I integrated Snyk and OWASP into the CI/CD pipeline. Snyk provided real-time scans of open source dependencies, identifying and suggesting solutions for known vulnerabilities. Meanwhile, OWASP tools were used to conduct comprehensive security assessments, focusing on identifying and mitigating risks associated with web applications.</p><p><b>Achieving Compliance Standards</b></p><p>My meticulous work ensured that the pipeline met the rigorous standards required by NIST, FIPS, and FedRAMP. I established automated checks and balances within the CI/CD process, ensuring that each code change went through comprehensive quality and security reviews before its implementation. This not only improved the overall security stance of applications, but also streamlined the compliance verification process, making it easier for Devo to demonstrate adherence to these critical standards.</p><p><b>Results</b></p><p>My contributions significantly improved the robustness of Devo's CI/CD pipeline, ensuring that code quality and security were maintained at the highest levels. The integration of SonarQube, Snyk and OWASP tools into the pipeline resulted in a safer and more efficient development process, aligned with the company's commitment to innovation and excellence.</p>",
          "technologies": [
            "Gitlab CI/CD",
            "Jenkins",
            "NIST",
            "FIPS",
            "FedRAMP",
            "SonarQube",
            "Snyk",
            "Owasp",
            "Kubernetes",
            "Jira"
          ],
          "links": [],
          "images": []
        },
        {
          "name": "Creating an alert system for monitoring with Prometheus",
          "description": "<p>I was instrumental in developing a comprehensive alert system designed to monitor performance and critical situations in production environments using Prometheus. Recognizing the need for real-time monitoring and rapid response mechanisms, I designed a solution that provided detailed insights into system performance and detected potential problems such as fraud, attacks and other anomalies.</p><p>To achieve this, I integrated Prometheus into Devo's infrastructure, setting up robust metrics and alerts collection mechanisms. I defined key performance indicators (KPIs) and key thresholds to maintain system health and stability.</p><p>In addition to setting up the alert system, I developed a comprehensive troubleshooting guide to assist the operations team in diagnosing and resolving problems quickly. This guide included step-by-step procedures to identify the root cause of the alerts, recommended actions, and escalation protocols. The guide ensured that team members had a clear understanding of how to handle different types of alerts, from minor performance degradations to critical system failures.</p><p>I also implemented automated early response actions to mitigate potential problems before they escalated. These automated actions included restarting services, redistributing load and dynamically scaling resources depending on the nature and severity of alerts. By automating these initial responses, I significantly reduced average recovery time (MTTR) and minimized the impact of problems on end users.</p><p>To improve the overall effectiveness of the monitoring system, I also designed protocols to handle critical system situations. These protocols outlined the roles and responsibilities of team members, communication strategies, and coordination efforts required during major incidents. This structured approach ensured a fast and coordinated response, reducing downtime and maintaining service reliability.</p><p>My contributions to creating the alert system not only improved the monitoring capabilities of Devo's platform, but also strengthened its security stance by enabling early detection of fraud and attacks. My work ensured that the system could maintain high performance and resilience, providing Devo's customers with a reliable and secure data analytics platform.</p>",
          "technologies": [
            "Prometheus",
            "Grafana",
            "Kubernetes",
            "Docker",
            "Elastic Stack",
            "Kibana",
            "Python",
            "Bash",
            "Ansible",
            "GIT"
          ],
          "links": [],
          "images": []
        }
      ],
      "images": [
        "devo1.png",
        "devo2.png"
      ]
    },
    {
      "name": "Comisión Europea",
      "short_description": "The European Commission is the executive arm of the European Union, responsible for proposing legislation, implementing decisions and managing daily affairs.",
      "thumbnail": "European_Commission_01.png",
      "period_time": {
        "start": "June 2017",
        "end": "January 2020",
        "current": false
      },
      "full_description": "<p>The European Commission is the executive arm of the European Union, responsible for proposing legislation, implementing decisions, defending EU treaties and managing the EU's daily affairs. It operates as a cabinet government, with 27 Commission members (one from each Member State) headed by a President.</p><p>Within the European Commission, the Directorate-General for Competition (DG COMP) plays a crucial role. DG COMP is responsible for establishing and implementing competition policy to ensure fair competition within the EU internal market. This includes enforcing antitrust laws, overseeing mergers and acquisitions and preventing monopolistic practices and state aid that could distort competition. DG COMP works to protect consumers and businesses by promoting innovation, ensuring a level playing field and improving economic efficiency.</p><p>I worked at DG COMP, contributing to the Commission's efforts to maintain competitive markets and promote economic growth throughout the European Union.</p>",
      "contribution": "<p>At the European Commission, I worked as a software architect on three projects, with a wide range of responsibilities that demonstrated my experience and leadership in software development.</p><ul><li><b>Non-functional requirements management and project definition</b>: Using Enterprise Architect, I was responsible for identifying and managing non-functional requirements, ensuring that each project was clearly defined and aligned with organizational objectives.</li><li><b>Prioritization of tasks</b>: Using Jira, I prioritized tasks effectively to ensure that the most critical elements were addressed in a timely manner.</li><li><b>Management of task dependencies</b>: I used Jira to manage dependencies between tasks, ensuring smooth progress and minimizing delays.</li><li><b>Selection of technology</b>: I was instrumental in selecting appropriate technologies for each project, ensuring that they were appropriate to meet the needs of the project.</li><li><b>Definition of Profiles of Team Members</b>: I defined the profiles and roles of the team members, ensuring that the team had the skills and experience needed to succeed.</li><li><b>Cooperation between teams</b>: Facilitated collaboration between different teams whose projects needed to be integrated, ensuring seamless integration and cooperation.</li><li><b>Quality control and testing</b>: I defined quality controls and test protocols, including unit testing using technologies like JUnit or Google Test/Valgrind, depending on the programming language.</li><li><b>Implementation of CI/CD systems</b>: I defined and implemented Continuous Integration and Continuous Deployment systems using tools like Bamboo and SonarQube.</li><li><b>Software development methodologies</b>: I applied the practices of Test-Based Development (TDD) and Behavioral Development (BDD) to ensure high-quality software development.</li><li><b>Agile methodology</b>: I used SCRUM as the main methodology for project management, encouraging an agile and efficient development process.</li></ul>",
      "links": [
        {
          "text": "Website of the European Commission, DG COMP",
          "url": "https://competition-policy.ec.europa.eu/index_en"
        }
      ],
      "projects": [
        {
          "name": "Definition of two RESTful APIs",
          "description": "<p>The first project involved the definition of two RESTful APIs that implemented the Richardson Level 3 Maturity Model, incorporating HATEOAS.</p><ul><li><b>Internal API</b>: The first API was intended to serve the internal staff of the European Commission.</li><li><b>External API</b>: The second API served as a platform for external staff.</li></ul>Both APIs had access control via a Single Session Start system called CAS. Data persistence was managed using both Oracle DB and MongoDB. Additionally, the APIs were integrated with an internal secure document storage project via a SOAP interface. The workflow of each procedure was managed using the State design pattern, and system administrators were notified of the status changes by email.",
          "technologies": [
            "Java",
            "Spring Security",
            "Spring MVC",
            "Spring Data",
            "Spring Documentation",
            "Spring IoC",
            "JPA",
            "Eclipselink",
            "WebLogic 12",
            "Oracle DB",
            "MongoDB",
            "Swagger",
            "JUnit",
            "AngularJS",
            "Selenium",
            "Maven",
            "GIT",
            "CAS",
            "Jira",
            "JUnit",
            "Bamboo",
            "SonarQube",
            "TDD",
            "BDD"
          ],
          "links": [
            {
              "text": "Documentation of e-leniency",
              "url": "https://competition-policy.ec.europa.eu/document/download/2fc568de-61ff-4aaf-9c9b-e03e96324ef7_en?filename=eleniency_guidance_access-notification.pdf"
            }
          ],
          "images": [
            "European_Commission_02.png"
          ]
        },
        {
          "name": "E-Confidentiality",
          "description": "<p>In the second project, I played a crucial role as a software architect, overseeing the development of a sophisticated system for negotiating confidential versions of legal documentation in antitrust proceedings. My contributions were fundamental to establishing and assigning dynamic verification groups responsible for managing online legal processes. These groups, composed of internal staff, were verified through the Central Authentication Service (CAS), a system previously implemented under my direction.</p><p>I designed the architecture of the system that governs the status of each document using the Status design pattern, which allows for reversal of changes, ensuring the integrity and accuracy of legal documents during the negotiation process.</p><p>In addition, I selected and integrated Oracle DB and MongoDB as database engines, capitalizing on their strengths to efficiently manage the complex data requirements of the project. I ensured that implementation followed the Richardson Level 3 Maturity Model, incorporating principles of HATEOAS (Hypermedia as the Engine of Application State). This approach ensured a robust and scalable system capable of supporting the intricate workflows involved in antitrust legal procedures.</p><p>Through my leadership and technical experience, I significantly improved the project's ability to provide a secure, reliable and easy-to-use platform for negotiating sensitive legal documents, thereby strengthening the effectiveness of antitrust enforcement actions.</p>",
          "technologies": [
            "AngularJS",
            "Ansible",
            "BDD",
            "Bamboo",
            "CAS",
            "Docker",
            "Eclipselink",
            "Enterprise Architect",
            "GIT",
            "IntelliJ IDEA",
            "JPA",
            "JUnit",
            "Java",
            "Jira",
            "Maven",
            "MongoDB",
            "Oracle DB",
            "Selenium",
            "SonarQube",
            "Spring Data",
            "Spring Documentation",
            "Spring IoC",
            "Spring MVC",
            "Spring Security",
            "Swagger",
            "TDD",
            "WebLogic 12"
          ],
          "links": [
            {
              "text": "E-confidentiality documentation",
              "url": "https://competition-policy.ec.europa.eu/index/it-tools/econfidentiality_en"
            }
          ],
          "images": []
        },
        {
          "name": "Semantic index of legal documents",
          "description": "<p>The third project, proposed by me, focuses on developing a sophisticated system for semantic indexing of legal documents. I acted as architect of this project, deeply involved in the programming process to ensure its success. The project uses clustering techniques, specifically the K-Means algorithm, applied to the legal document dataset of the antitrust department. The indexing process is integrated into a microservices designed with the gRPC framework, implemented in C++14 to ensure maximum efficiency and performance.</p><p>The architecture of these microservices follows the paradigm of Command and Query Responsibility Segregation (CQRS), deployed in a service pool to ensure resilience and fast response times. Semantic search capability is enhanced by a neural network trained in the dataset of antitrust legal documents, using the TensorFlow framework.</p><p>This dual service approach not only facilitates high-speed semantic searches, but also ensures robust and scalable indexing of complex legal documents. The system design emphasizes resilience, efficiency and accuracy, making it a vital tool for managing and retrieving legal documents in the antitrust department. My initiative and active participation in architecture and programming were crucial to the project's success.</p>",
          "technologies": [
            "AngularJS",
            "Ansible",
            "Bamboo",
            "C++",
            "CUDA",
            "Cassandra",
            "Docker",
            "Eclipselink",
            "Enterprise Architect",
            "GIT",
            "Google Test",
            "Groovy",
            "IntelliJ IDEA",
            "JPA",
            "JUnit",
            "Java",
            "Jira",
            "Maven",
            "Microservices",
            "OpenCL",
            "Oracle DB",
            "Selenium",
            "SonarQube",
            "Spring Data",
            "Spring Documentation",
            "Spring MVC",
            "Spring Security",
            "Swagger",
            "TensorFlow",
            "Valgrind",
            "WebLogic 12",
            "gRPC"
          ],
          "links": [],
          "images": []
        },
        {
          "name": "Development of a renewable energy distribution system",
          "description": "<p>The fourth project involves the development of a renewable energy distribution system within the electricity grid, with the aim of normalizing and stabilizing electricity consumption over time to maximise the use of renewable energies.</p><p>The system integrates a wide variety of technologies to achieve its objectives. At the core of the communication system is a Kafka-based messaging cluster, where communication with devices is managed through Avro schemes. An intermediate \"gateway\" is implemented using Raspberry Pi, responsible for sending telemetry data and receiving commands. This gateway system was developed in Go, using the ModBus communications protocol in its serial and TCP versions, with TCP communications secured via a VPN.</p><p>The software management for this project is managed through the BalenaIO platform, which facilitates the deployment and operation of gateway devices. Continuous Integration and Continuous Deployment (CI/CD) processes are managed using CircleCI, ensuring an efficient and uninterrupted development workflow.</p><p>In addition, I created a statistical analyzer at Groovy for telemetry data intake, providing critical information about energy consumption patterns and system performance.</p><p>My practical approach and technical expertise were essential to tackling the challenges of renewable energy distribution, and my contribution to harnessing advanced technologies and developing robust communication protocols underlines my significant role in this innovative project aimed at improving the stability and efficiency of the use of renewable energy within the electricity grid.</p>",
          "technologies": [
            "Go",
            "Unit Test",
            "BalenaIO",
            "RaspberryPI",
            "Modbus",
            "Python",
            "Make",
            "Docker",
            "Kubernetes",
            "GCP",
            "Azure",
            "IoTHub",
            "Kafka",
            "Avro Schemas",
            "Ansible",
            "Elastic Search",
            "Kibana",
            "Jira",
            "Groovy"
          ],
          "links": [],
          "images": []
        }
      ],
      "images": []
    },
    {
      "name": "Panel Sistemas",
      "short_description": "Panel Systems is a technology solutions company offering software, consulting and development services to various industries.",
      "thumbnail": "panel_sistemas.png",
      "period_time": {
        "start": "In September 2015",
        "end": "June 2017",
        "current": false
      },
      "full_description": "<p>Panel Sistemas is a leading technology solutions company, specializing in software development, consulting and IT services. Founded in Spain, it serves various industries with leading clients such as Telefónica, BBVA, Santander, Repsol and El Corte Inglés.</p><b>Services offered</b><lu><li>Software development: Tailored software solutions.</li><li>Consulting: IT strategy and optimization.</li><li>Maintenance and Support: Continuous application support.</li><li>Quality assurance: Complete software testing.</li><li>Digital transformation: transition from business to digital platforms.</li></lu><b>Experience in the industry</b><lu><li>Finances</li><li>Telecommunications</li><li>Energy</li><li>Retail</li></lu>",
      "contribution": "<p>At Panel Systems, I worked as a functional analyst on three projects. I also worked as a senior programmer in the post-decision phase. My responsibilities as a functional analyst included:</p><ul><li>Analysis of non-functional requirements and decision-making on the exact implementation of the solution (Redmine)</li><li>Creating sub-tasks with less granularity to achieve objectives (Redmine)</li><li>Estimated time (Redmine)</li><li>Definition and implementation of the project structure in the specified technologies</li><li>Definition of the coverage and quality of unit tests (JUnit, Google Test, Valgrind)</li><li>Implementation of IC/CD systems (Jenkins)</li><li>Use of SCRUM as a development methodology</li><li>Application of TDD and BDD in software development</li><li>Teaching training sessions on TDD, BDD, Neural Networks, Clean Code and more</li></ul>",
      "links": [
        {
          "text": "Website of the Systems Panel",
          "url": "https://www.panel.es/"
        }
      ],
      "projects": [
        {
          "name": "Modernisation of maritime and air transport messaging: replacement of IATA by XML/JSON",
          "description": "<p>The first of the projects I worked on involved the implementation of a messaging platform for maritime and air transport. This project successfully replaced the outdated IATA standard, based on flat text and prone to human error due to its reliance on the position of the text chain, with a more modern, readable and error-resistant format based on XML/JSON.</p><p>To achieve this, I defined an analyzer that translated messages from the old format to either of the two modern standards through a Restful API that met the Richardson Level 3 maturity model. This API not only provided an entry point for message translation, but also facilitated intercommunication with other platforms around the world and storage of these communications to ensure the traceability of packet transit globally. The project objectives required a high availability structure and a replicated database system based on MongoDB, implemented through a cluster of servers with each replicated fragment.</p>",
          "technologies": [
            "Java",
            "Spring Security",
            "Spring MVC",
            "Spring Data",
            "Spring Documentation",
            "JPA",
            "Hibernate",
            "Wildfly/JBoss",
            "MongoDB",
            "RabbitMQ",
            "JUnit",
            "JSF",
            "Primefaces",
            "GWT",
            "AWS",
            "Phonegap",
            "Hadoop",
            "Selenium",
            "Maven",
            "GIT",
            "Jenkins",
            "Redmine",
            "IntelliJ IDEA",
            "Docker",
            "Ansible"
          ],
          "links": [],
          "images": [
            "iata.png"
          ]
        },
        {
          "name": "Intelligent terminal management of Iberdrola with Siemens",
          "description": "The second project was a joint project with Siemens to create the Intelligent Management Infrastructure of Iberdrola's terminals. These terminals were stored in a non-relational MongoDB database, which for obvious reasons were several clusters, with load balancing and replicated fragments. The information from each point was stored in the cluster by geographic proximity, provided the server could assume the volume of data that included the said node. This data consumption was generated for one year using the JCPOA system and this data was then maintained at a time-based level called the JCPOA, and this data was then maintained at a time-based level called the JCPOA.",
          "technologies": [
            "C++",
            "Google Test",
            "Valgrind",
            "cLion",
            "Boost",
            "gRPC",
            "Microservices",
            "Java",
            "RabbitMQ",
            "JPA",
            "Hibernate",
            "Apache Tomcat",
            "MongoDB",
            "JUnit",
            "JSF",
            "Primefaces",
            "Hadoop",
            "Maven",
            "GIT",
            "Jenkins",
            "Jira",
            "IntelliJ IDEA",
            "Docker",
            "Ansible",
            "Kubernetes",
            "JNLP",
            "SNMP",
            "Spring Security",
            "Spring MVC",
            "Spring Data",
            "Spring Documentation",
            "Spring IOT"
          ],
          "links": [],
          "images": [
            "iberdrola.svg",
            "siemens.png"
          ]
        },
        {
          "name": "Monitoring and care system for persons with disabilities or the elderly for Securitas Direct",
          "description": "<p>The third project, executed for Securitas Direct, involved the creation of a comprehensive monitoring and care system for people with disabilities or the elderly. The system identified the status of the user based on various sensors distributed throughout their home, including presence sensors, door opening sensors, and personal fall sensors. This data was collected to provide detailed information about the user's activities, which was not only stored and accessible for consultation, but was also capable of generating alarms based on the individual's typical behavior patterns.</p><p>In addition, the app included a mobile component developed as a hybrid app. This mobile version used sensors to identify falls, track an individual's GPS position, and more.</p>",
          "technologies": [
            "C++",
            "Google Test",
            "Valgrind",
            "cLion",
            "Boost",
            "gRPC",
            "Microservices",
            "Java",
            "AWS",
            "Spring Security",
            "Spring MVC",
            "Spring Data",
            "Spring Documentation",
            "Spring IoC",
            "Spring Batch",
            "RabbitMQ",
            "JPA",
            "Hibernate",
            "Apache Tomcat",
            "Oracle DB",
            "JUnit",
            "Ionic",
            "Typescript",
            "Hadoop",
            "Selenium",
            "Jasmine",
            "Maven",
            "GIT",
            "Jenkins",
            "Jira",
            "Confluence",
            "IntelliJ IDEA",
            "Docker",
            "Ansible",
            "Kubernetes"
          ],
          "links": [],
          "images": []
        }
      ],
      "images": []
    },
    {
      "name": "Grupo Prisa",
      "short_description": "Grupo PRISA is a Spanish media conglomerate, known for its influential newspapers, radio stations and educational publications.",
      "thumbnail": "prisa.png",
      "period_time": {
        "start": "March 2012",
        "end": "May 2015",
        "current": false
      },
      "full_description": "<p>Grupo PRISA, formally known as Promotora de Informaciones, S.A., is a prominent Spanish media conglomerate with significant influence in the Spanish-speaking world. Founded in 1972 by Jesús de Polanco, PRISA has grown to become one of the largest media companies in Spain and Latin America, encompassing a wide range of media, including newspapers, radio stations, television channels and educational publications.</p><p>Key aspects of PRISA Group include:</p><ul><li><strong>Newspapers:</strong>PRISA's flagship newspaper is <em>The country</em>, one of Spain's most widely read and respected newspapers. Launched in 1976 during Spain's democratic transition,<em>The country</em>It quickly became a symbol of the new democratic era, offering high-quality journalism and a progressive editorial stance. The newspaper covers a wide range of topics, from national and international news to culture, economics and sports. It has also expanded its reach with a robust online presence, serving millions of readers worldwide.</li><li><strong>Radio:</strong>In the radio sector, PRISA owns Cadena SER, the leading radio network in Spain. Cadena SER is known for its information programming, tertulia programs and sports coverage. It has a substantial audience and is known for its complete coverage of news and tertulia programs that address current affairs, politics and social issues. Other prominent broadcasters under PRISA's umbrella include Los 40 Principales, a popular music broadcaster that plays contemporary hits, and Cadena Dial, which focuses on music in Spanish.</li><li><strong>Television:</strong>PRISA has also ventured into television, with its channel <em>CNN+</em>Having been a significant player in the Spanish news market until its closure in 2010, despite this, PRISA continues to have a presence in the television sector through various partnerships and content production.</li><li><strong>Educational publications:</strong>Beyond news and entertainment, PRISA is an important player in the educational publishing industry through its subsidiary, Santillana. Founded in 1960, Santillana is a leading publisher of educational materials in Spain and Latin America. It offers a wide range of textbooks, digital content and educational resources for students and teachers, making significant contributions to education in the Spanish-speaking world.</li><li><strong>Digital transformation:</strong>In recent years, PRISA has embraced digital transformation, adapting to the changing media landscape. The company has invested heavily in digital platforms, mobile applications and online content to reach a wider audience and remain relevant in the digital age. <em>The country</em>For example, it has a strong digital presence, with a website that attracts millions of visitors each month and a variety of multimedia content, including videos, podcasts and interactive features.</li><li><strong>Global influence:</strong>PRISA's influence extends beyond Spain and Latin America. It has formed strategic partnerships with international media companies and expanded its reach to other regions. The company's content is consumed by millions of people worldwide, making it a significant cultural and information bridge between Spain, Latin America and the rest of the world.</li></ul>",
      "contribution": "<p>I have extensive experience working as a remote senior programmer on three important projects. In this role, I was entrusted with a variety of critical responsibilities that required both technical expertise and strong communication skills. One of my main duties was to attend meetings with the product owner to define the detailed requirements of the project. This involved a thorough analysis of the project objectives and break them down into specific and processable tasks.</p><p>Coordination with external teams was another important aspect of my role. I worked closely with collaboration teams based in South America, India and China. This international coordination required me to effectively manage different time zones and cultural differences. To facilitate fluid communication and collaboration, I translated and interpreted the requirements into Chinese. This linguistic skill was crucial to overcome communication gaps and ensure that all team members, regardless of their location, had a clear and accurate understanding of the project requirements.</p><p>Innovation and efficiency were key areas of focus in my role. I participated in rainy ideas sessions to develop and implement new tools aimed at improving automation and team productivity. These tools were designed to streamline workflows, reduce manual effort and improve overall efficiency of the development process. By introducing these innovations, I was able to contribute to a more productive and effective team environment.</p><p>Detailed project planning was another critical responsibility. I used the SCRUM methodology to ensure that all tasks were organized and managed effectively throughout the project lifecycle. This involved creating detailed plans, setting realistic timelines, and continually monitoring progress to ensure that project milestones were met. The use of SCRUM allowed a flexible and iterative approach to project management, allowing the team to adapt to changes and address challenges quickly.</p><p>Overall, my experience as a senior remote programmer has provided me with a diverse skill set and a deep understanding of effective project management in a remote and global work environment. My ability to define detailed requirements, coordinate with international teams, innovate to improve productivity and manage projects using SCRUM has allowed me to contribute significantly to the success of the projects I have been involved in.</p>",
      "links": [
        {
          "text": "The website of Grupo Prisa",
          "url": "https://www.prisa.com/es"
        }
      ],
      "projects": [
        {
          "name": "Application of the educational package visor",
          "description": "<p>This application was meticulously designed to be compatible with low-end devices, ensuring it could reach a wider user base without compromising performance. It was essential that the application interacted fluently with users, providing a seamless and engaging experience. In addition, the application was equipped with functionality to track and send users' progress to the server, facilitating effective monitoring and evaluation of their learning journey.</p><p>A key feature of the application was its ability to manage educational packages that met the SCORM (Shared Content Object Reference Model) standard, which is widely used in the field of e-learning to create and deliver interactive and adaptive learning content. To ensure compatibility with previous versions, the application was also designed to support older versions of educational packages. This dual compatibility ensured that users could access a wide range of old educational content, both modern and old, thus improving the usefulness and appeal of the application in various educational contexts.</p>",
          "technologies": [
            "Java",
            "Android Studio",
            "XCode",
            "Objective-C",
            "Dagger",
            "SCORM",
            "HTML",
            "JavaScript",
            "Bootstrap",
            "jQuery",
            "Jira",
            "GIT",
            "Confluence"
          ],
          "links": [],
          "images": []
        },
        {
          "name": "Project for standardisation of education packages",
          "description": "<p>The second project arose from the need to standardize educational packages. In an effort to save costs associated with migrating Flash to HTML5 under the SCORM standard, the decision was made to develop a translation tool from Flash to HTML5. This tool facilitated the conversion of educational content from Flash to HTML5, ensuring compatibility with the SCORM standard.</p><p>Using technologies such as QEmu, KVM, and Xen, the new versions were rigorously evaluated to ensure their stability and functionality. This comprehensive testing process was crucial in identifying and solving potential problems prior to deployment, thus maintaining the integrity of educational packages. The project not only achieved cost savings and improved efficiency, but also provided a robust framework for future updates and improvements, ensuring the longevity and adaptability of educational content.</p>",
          "technologies": [
            "C++",
            "Linux",
            "Flash",
            "HTML",
            "JavaScript",
            "AngularJS",
            "Bootstrap",
            "SCORM",
            "jQuery",
            "Jira",
            "GIT",
            "Confluence",
            "QEmu",
            "KVM",
            "Xen",
            "Bash",
            "NginX",
            "Valgrind"
          ],
          "links": [],
          "images": []
        },
        {
          "name": "Project of educational platform",
          "description": "<p>The third project was developed using C# on the .NET platform, designed as a comprehensive environment for teachers and education professionals. This platform enabled users to manage various educational tasks, including managing students, managing educational packages and analyzing their results. It also facilitated programming and execution of media server-related tasks for broadcast purposes.</p><p>In addition, the platform had a high-resolution audio and video communication center via IP, improving real-time interactions between educators and students. This robust system supported a seamless and efficient workflow, ensuring that all educational activities were effectively managed and executed within a unified environment.</p>",
          "technologies": [
            "C#",
            ".NET",
            "IIS",
            "Windows Server",
            "Microsoft SQL Server",
            "Jira",
            "GIT",
            "Confluence"
          ],
          "links": [],
          "images": []
        }
      ],
      "images": []
    },
    {
      "name": "Intelygenz",
      "short_description": "Intelygenz is a technology company specialising in artificial intelligence, machine learning and tailor-made software solutions for various industries.",
      "thumbnail": "intelygenz.png",
      "period_time": {
        "start": "January 2010",
        "end": "January 2012",
        "current": false
      },
      "full_description": "<p>The third project was developed using C# on the .NET platform, designed as a comprehensive environment for teachers and education professionals. This platform enabled users to manage various educational tasks, including managing students, managing educational packages and analyzing their results. It also facilitated programming and execution of media server-related tasks for broadcast purposes.</p><p>In addition, the platform had a high-resolution audio and video communication center via IP, improving real-time interactions between educators and students. This robust system supported a seamless and efficient workflow, ensuring that all educational activities were effectively managed and executed within a unified environment.</p>",
      "contribution": "<p>As a Senior Programmer, I contributed to three significant projects. The first project was an application for Antena 3 Television, developed natively for Android. This application served as a real-time interactive interface with television content, updated through inaudible markers embedded in the audio. The audio was intercepted by the application, using a custom solution developed in the Android NDK to ensure high performance and low battery consumption. This solution modified the audio by adding separate echoes by specific time distances, which were interpreted in a binary manner.</p>",
      "links": [
        {
          "text": "The website of Intelygenz",
          "url": "https://intelygenz.com/"
        }
      ],
      "projects": [
        {
          "name": "Project Antenna 3 Television",
          "description": "<p>The first project involved the development of an application for Antena 3 Television, built natively for Android. This application served as a real-time interactive interface with television content, dynamically updated using inaudible markers embedded in audio.</p><p>The modified audio included echoes separated by specific time intervals, which the application interpreted in binary format. This innovative approach allowed the application to seamlessly interact with the television broadcast, providing users with an enhanced and engaging viewing experience.</p>",
          "technologies": [
            "Java",
            "Android Studio",
            "Android NDK",
            "Jira",
            "GIT",
            "Confluence"
          ],
          "links": [
            {
              "text": "Documentation of the antenna 3 TV application",
              "url": "https://www.atresmediacorporacion.com/a3document/2012/05/24/DOCUMENTS/00012/00012.pdf"
            }
          ],
          "images": [
            "intelygenz_01.jpeg"
          ]
        },
        {
          "name": "Project document manager for BBVA",
          "description": "<p>The second project involved the development of a document manager for the BBVA bank, implemented in C# within the .NET environment. This system was designed to connect with external tools based on the Google App Engine framework.</p><p>In addition, the document manager integrated BBVA's workflow and business logic, enabling smooth interaction with other banking entities. This implementation not only streamlined document management processes, but also ensured that the bank's operations were aligned with industry standards and best practices, thus improving efficiency and collaboration between different departments and external partners.</p>",
          "technologies": [
            "C#",
            ".NET",
            "IIS",
            "Windows Server",
            "Microsoft SQL Server",
            "Cassandra",
            "HTML",
            "JavaScript",
            "Bootstrap",
            "jQuery",
            "Jira",
            "GIT",
            "Confluence"
          ],
          "links": [],
          "images": [
            "bbva.jpg"
          ]
        },
        {
          "name": "Collaborative Front project",
          "description": "<p>The third project involved the development of a collaborative front-end for the BBVA bank, using both Java and JavaScript. This project was integrated with the NACAR environment, a platform designed to improve the functionality and user experience of banking applications.</p><p>A significant achievement of this project was the creation of an on-screen library of gestures and actions, known as IRIS. This library was designed to improve user interaction by providing intuitive and efficient ways to perform various tasks. The IRIS library improved the overall user experience, making the application more receptive and easy to use.</p>",
          "technologies": [
            "Java",
            "Spring Security",
            "Spring MVC",
            "Spring Data",
            "Spring Documentation",
            "JPA",
            "Hibernate",
            "Websphere",
            "Oracle DB",
            "JUnit",
            "JSF",
            "Maven",
            "GIT",
            "Jira",
            "Confluence",
            "GIT",
            "Eclipse"
          ],
          "links": [],
          "images": [
            "bbva.jpg"
          ]
        }
      ],
      "images": []
    },
    {
      "name": "UAH",
      "short_description": "The University of Alcalá de Henares is a prestigious Spanish institution known for its rich history and various academic programs.",
      "thumbnail": "uah.svg",
      "period_time": {
        "start": "January 2006",
        "end": "January 2009",
        "current": false
      },
      "full_description": "<p>The University of Alcalá de Henares, commonly known as the University of Alcalá, is a renowned public university located in Alcalá de Henares, a historic city near Madrid, Spain. Founded in 1499 by Cardinal Cisneros, it is one of the oldest universities in Spain and has a rich heritage that combines tradition with modernity.</p><p>The University of Alcalá is celebrated for its commitment to academic excellence and innovation. It offers a wide range of undergraduate, postgraduate and doctoral programs in various fields of study, including humanities, social sciences, natural sciences, engineering, health sciences and law. The university is particularly known for its solid programs in literature, linguistics and Spanish language studies, attracting students and academics from all over the world.</p><p>One of the most notable features of the university is its historic campus, which is a UNESCO World Heritage site. The campus includes impressive examples of Spanish Renaissance architecture, such as the College of San Ildefonso, the main building of the university, which has a beautiful courtyard and a historic chapel.</p><p>In addition to its historic campus, the University of Alcalá has modern facilities equipped with the latest technology to support cutting-edge research and innovative teaching methods. The university's libraries, laboratories and research centers provide students and professors with the resources they need to pursue their academic and professional goals. The university also promotes a strong research culture and encourages collaboration with institutions and industries both nationally and internationally.</p><p>The University of Alcalá is dedicated to fostering a diverse and inclusive community. It welcomes students from all over the world and offers a range of support services to help international students integrate into campus life. The vibrant student life of the university includes numerous cultural, social and sporting activities, providing students with opportunities to interact with the wider community and develop their personal and professional skills.</p><p>A key aspect of the University of Alcalá's mission is its commitment to social responsibility and sustainable development. The university actively participates in initiatives that promote environmental sustainability, social justice and community development. It collaborates with local, national and international organizations to address urgent global challenges and contribute to the well-being of society.</p><p>The University of Alcalá's alumni network is a testament to its impact and influence. The university's graduates have achieved significant success in various fields, including academia, business, government and the arts. The university maintains strong connections with its alumni, fostering a supportive and committed community that continues to contribute to the university's legacy.</p><p>In summary, the University of Alcalá de Henares is a distinguished institution that combines historical importance with a progressive approach to education.</p>",
      "contribution": "<p>My role as a researcher at the university was within the TIFyC research group, where I had a range of responsibilities focused on advancing the field of technology and artificial intelligence. One of my main tasks was to conduct comprehensive research on the state of the art in various areas, including accessibility issues, AI algorithms, artificial vision and biometric systems. This involved staying up to date with the latest developments, evaluating new methodologies and identifying potential areas of innovation.</p><p>In addition to my research duties, I actively participated in collaborations with research groups from different universities. These collaborations were aimed at encouraging knowledge exchange, promoting interdisciplinary research and promoting innovative projects. By working closely with other researchers, we were able to combine our experience and resources to tackle complex challenges and expand the boundaries of our respective fields.</p><p>Another key aspect of my role was preparing detailed reports on our research findings. These reports documented our methodologies, results and conclusions, providing a valuable resource for future research and contributing to the wider scientific community. My ability to communicate our findings clearly and effectively was crucial to ensuring that our work had a meaningful impact.</p><p>In addition, I participated in the study and application for State aid and grants for research and development (R&amp;D) projects, which required a thorough understanding of the financing landscape and the ability to develop compelling proposals that demonstrated the importance and potential impact of our research.</p><p>As part of my responsibilities, I also served as an assistant professor, teaching courses on Artificial Intelligence and Artificial Vision Systems. In this capacity, I was responsible for imparting knowledge to students, designing course materials and guiding them through complex concepts and practical applications. My teaching role allowed me to share my passion for AI and artificial vision with the next generation of researchers and professionals, while remaining committed to the academic community.</p>",
      "links": [
        {
          "text": "Website of the University of Alcalá",
          "url": "https://uah.es/"
        }
      ],
      "projects": [
        {
          "name": "Project of the research group",
          "description": "<p>One of the significant projects carried out by our research group focused on researching innovative devices designed to improve interaction for individuals with visual, auditory or motor disabilities. The main objective of this research was to develop and refine technologies that could facilitate more intuitive and accessible interactions with various types of systems, including desktop computers, laptops and mobile devices.</p><p>Our team explored a wide range of assistive technologies and user interface improvements aimed at overcoming the challenges faced by people with disabilities. This included developing specialized input devices, adaptive software solutions, and advanced user interface designs that specifically tailored to the needs of users with visual, auditory, and motor disabilities. By focusing on these areas, we sought to create a more inclusive digital environment that empowers users to interact with technology more effectively and independently.</p><p>The research also involved extensive user testing and collaboration with individuals with disabilities to ensure that the solutions developed were practical, easy to use, and really beneficial. By integrating feedback from real users, our research group was able to make significant strides in creating devices and applications that not only met accessibility standards, but also improved the overall user experience for people with disabilities.</p><p>This project exemplifies our commitment to leveraging technology to remove barriers and improve the quality of life for people with disabilities, making technology accessible and usable to everyone, regardless of their physical abilities.</p>",
          "technologies": [
            "Java",
            "Android Studio",
            "Android",
            "Linux",
            "C++",
            "Anjuta",
            "Qt",
            "PIC",
            "Arduino",
            "SVN",
            "C#",
            ".NET",
            "Mono"
          ],
          "links": [],
          "images": [
            "tifyc.jpg"
          ]
        },
        {
          "name": "Communication system for biometric devices",
          "description": "<p>The second project I worked on involved developing a standardized communication system for biometric devices. The goal was to enable seamless messaging and collaboration between devices from various manufacturers. To achieve this, we integrated a remote procedure call system (RPC) within the devices themselves. This RPC system ensured that communication between devices remained transparent regardless of the programming language or operating system used.</p><p>The project required careful consideration of interoperability issues, as biometric devices often come with proprietary communication protocols and diverse technical specifications. By implementing a standardized RPC system, we were able to abstract the underlying differences and create a unified communication protocol. This protocol facilitated efficient data exchange and operational coordination across a wide range of biometric devices.</p><p>In addition, the communication system was designed to be highly robust and secure, given the sensitive nature of biometric data. We incorporated encryption and authentication mechanisms to protect data integrity and prevent unauthorized access. The end result was a reliable, multi-platform solution that significantly improved the interoperability and functionality of biometric systems.</p><p>This project not only improved the compatibility of devices but also paved the way for future advances in biometric technology, allowing manufacturers to focus on innovation without worrying about communication barriers.</p>",
          "technologies": [
            "Java",
            "Linux",
            "C++",
            "Anjuta",
            "SVN",
            "C#",
            ".NET",
            "Mono"
          ],
          "links": [],
          "images": []
        },
        {
          "name": "Project website of the research group",
          "description": "<p>The third project involved the continuous creation and maintenance of the research group's website using the Joomla Content Management System (CMS). This project required not only the initial development of an easy-to-use and visually appealing website, but also the continuous updating and improvement of its features and content to meet the evolving needs of the research group.</p><p>The website served as a central hub for the research group's activities, providing access to future publications, project updates and events. Taking advantage of Joomla's robust framework, I ensured that the website was both secure and scalable, capable of handling a growing volume of content and user interactions. The CMS allowed for easy content management, enabling research group members to contribute and update information without requiring extensive technical knowledge.</p><p>In addition to technical implementation, I focused on optimizing website performance and accessibility. This included ensuring fast load times, implementing responsive design for multi-device compatibility, and adhering to accessibility standards to make the site usable for all visitors. Regular maintenance tasks included updating the Joomla core and extensions, monitoring site performance, and addressing any security vulnerabilities in a timely manner.</p><p>In short, this project demonstrated my ability to develop and manage a dynamic web presence that effectively supports the goals and activities of a specialized group, using the powerful features of the Joomla CMS.</p>",
          "technologies": [
            "Java",
            "Linux",
            "C++",
            "Anjuta",
            "SVN",
            "C#",
            ".NET",
            "Mono"
          ],
          "links": [],
          "images": [
            "tifyc.jpg"
          ]
        },
        {
          "name": "Contributions to the research group",
          "description": "<p>During my stay in the research group, I contributed in various capacities. My support work encompassed a variety of tasks aimed at facilitating the group's objectives. I also organized and conducted specialized seminars focused on robotics, sharing advanced knowledge and the latest developments in the field with my colleagues and students.</p><p>In addition, I served as an assistant professor, where I taught subjects such as Artificial Intelligence and Artificial Vision. In this role, I was responsible for preparing and dictating lectures, attending course design and providing guidance to students on complex topics related to AI technologies and computer vision. My participation in these subjects helped bridge the gap between theoretical concepts and practical applications for students.</p><p>Beyond teaching and support roles, I actively participated in extracurricular activities, including the Hispabot robotics competition. I competed in the maze-resolution mode, where I applied my experience in robotics and AI to design and program robots capable of navigating and solving maze-resolving. This experience not only improved my technical skills, but also demonstrated my ability to apply research in competitive real-world environments.</p>",
          "technologies": [
            "C",
            "C++",
            "Arduino",
            "PIC",
            "Mathlab",
            "Octave",
            "Java",
            "Python"
          ],
          "links": [],
          "images": [
            "hispabot.jpeg"
          ]
        }
      ],
      "images": []
    },
    {
      "name": "Knowcentury",
      "short_description": "Small company dedicated to creating websites",
      "thumbnail": "knowcentury.png",
      "period_time": {
        "start": "January 2005",
        "end": "July 2005",
        "current": false
      },
      "full_description": "Small company dedicated to creating websites",
      "contribution": "<p>During my early college years, in order to pay for my studies, I worked as a junior web programmer using CMS at Knowcentury.</p>",
      "links": [],
      "projects": [
        {
          "name": "Development of websites",
          "description": "<p>Implementation of web pages using CMS such as Joomla, Drupal and Moodle.</p>",
          "technologies": [
            "Joomla",
            "PHP",
            "JavaScript",
            "MySQL",
            "HTML"
          ],
          "links": [],
          "images": []
        }
      ],
      "images": []
    },
    {
      "name": "IBM",
      "short_description": "IBM, a global technology company, specializes in cloud computing, AI and hardware, providing innovative solutions for businesses around the world.",
      "thumbnail": "ibm.svg",
      "period_time": {
        "start": "In September 2003",
        "end": "December 2004",
        "current": false
      },
      "full_description": "<p>IBM, or International Business Machines Corporation, is a world-renowned technology company with a rich history spanning more than a century. Founded in 1911 and headquartered in Armonk, New York, IBM has been constantly at the forefront of technological innovation, influencing numerous sectors with its pioneering solutions. Today, IBM is a leader in cloud computing, artificial intelligence (AI) and enterprise hardware, offering a complete suite of products and services that cater to businesses of all sizes.</p><p>One of IBM's most significant contributions to technology is its development of powerful AI systems, particularly the IBM Watson platform. Watson is designed to leverage natural language processing and machine learning to analyze large amounts of data, providing information and enabling automation in various industries, including health, finance and customer service. IBM Watson's capabilities in data analysis and predictive analytics help organizations make more informed decisions, improve operational efficiency, and drive innovation.</p><p>In addition to AI, IBM has made substantial advances in cloud computing with its IBM Cloud platform. This robust platform offers a wide range of cloud services, including infrastructure as a service (IaaS), platform as a service (PaaS), and software as a service (SaaS). IBM Cloud is designed to support both public and private cloud environments, enabling companies to deploy and manage applications with greater flexibility and security.</p><p>IBM's hardware solutions have also played a key role in the company's success. The IBM Z series of mainframes, for example, are known for their reliability, security, and performance, particularly in industries that require robust data processing capabilities, such as banking and finance. These mainframes are designed to handle large-scale transaction processing and data management, ensuring business continuity and operational efficiency.</p><p>Another key area of IBM's expertise is its commitment to research and development (R&amp;D). IBM invests heavily in R&amp;D, constantly pushing the boundaries of what is possible in technology. The company's innovations have led to numerous advances, including the development of quantum computing. IBM Quantum is an advanced computing platform that leverages the principles of quantum mechanics to solve complex problems that are beyond the capabilities of classical computers. This cutting-edge computer technology has the potential to revolutionize industries by enabling new approaches to problem solving and optimization.</p><p>In addition, IBM's commitment to sustainability and corporate social responsibility (CSR) reflects its dedication to having a positive impact on the world. The company has implemented various initiatives aimed at reducing its environmental footprint, promoting diversity and inclusion, and supporting education and community development. IBM's CSR efforts underline its belief in using technology as a force for good, driving positive change in society.</p><p>In short, IBM is a global leader in technology, offering innovative solutions in AI, cloud computing, and enterprise hardware. With a strong emphasis on research and development, the company continues to drive technological advances that shape the future of various industries. IBM's commitment to sustainability and social responsibility further strengthens its reputation as a progressive, socially conscious organization. Through its complete suite of products and services, IBM empowers companies to achieve their goals and navigate the complexities of the digital age.</p>",
      "contribution": "<p>During this period, my main responsibility was to conduct extensive research into the use of the IBM System Z/390s mainframe for system virtualization. This project involved using Qemu, an open source emulator, to facilitate the virtualization process. The goal was to enable the use of remote systems by creating virtualized environments on the IBM mainframe. These virtual systems were to operate under the Suse Linux Enterprise Edition operating system, ensuring a robust and secure platform for various applications and services.</p><p>My role required a comprehensive understanding of the architecture and capabilities of the IBM System Z/390s. I focused on exploring how Qemu could effectively integrate with the mainframe to achieve efficient virtualization. This involved configuring and optimizing the mainframe to support multiple virtual machines, each running its own instance of the Suse Linux Enterprise Edition.</p><p>In addition, I investigated several aspects of system virtualization, including resource allocation, performance optimization, and security measures. Ensuring that virtualized systems could operate seamlessly and efficiently on the mainframe was paramount. This involved thorough testing and fine-tuning of virtual environments to meet the specific needs of remote system users. The project aimed to leverage the power and reliability of the IBM System Z/390s to provide scalable and secure virtualized solutions for enterprise applications.</p>",
      "links": [],
      "projects": [
        {
          "name": "Development of websites",
          "description": "<p>Implementation of web pages using CMS such as Joomla, Drupal and Moodle.</p>",
          "technologies": [
            "Joomla",
            "PHP",
            "JavaScript",
            "MySQL",
            "HTML"
          ],
          "links": [],
          "images": [
            "ibm_system_z.jpg",
            "kvm.png",
            "suse.png"
          ]
        }
      ],
      "images": []
    }
  ],
  "educations": {
    "university": [
      {
        "university_name": "A.U.A.",
        "title": "Master's degree in Artificial Intelligence in information and communication technologies",
        "period_time": {
          "start": "In September 2007",
          "end": "June 2009",
          "current": false
        },
        "summary": "Artificial intelligence and machine learning. Supervised, unsupervised and reinforced. Symbolic learning. Classification and regression models. Model optimization. Deep networks. Multilayer networks, retropropagation. Loss functions. Hyperparameters and learning strategies. Convoltional networks. Image recognition. Sequential and recurrent networks. LSTM models. Parallelisation and computing techniques in GPU-based architectures. Vectoring techniques. Programming with tensorflow and theano. Automated learning. Scalable learning. Frameworks for scalability in computer clusters. Applications in medicine, finance, automated driving, etc.",
        "images": [
          "uah.svg"
        ],
        "thumbnail": "uah.svg"
      },
      {
        "university_name": "A.U.A.",
        "title": "Technical engineering in computer science",
        "period_time": {
          "start": "September 2001",
          "end": "June 2007",
          "current": false
        },
        "summary": "With honors in: Artificial intelligence, diffuse logic, systems of artificial vision, physics II, mathematical analysis, data structure, networks.",
        "images": [
          "uah.svg"
        ],
        "thumbnail": "uah.svg"
      }
    ],
    "complementary": [
      {
        "institution": "The Linux Foundation",
        "title": "This Regulation shall enter into force on the twentieth day following that of its publication in the Official Journal.",
        "period_time": {
          "start": "In September 2015",
          "end": "",
          "current": true
        },
        "summary": "Advanced management of Linux systems, including those related to the kernel. Perform advanced management of block storage and file systems, as well as advanced network authentication and system security, including firewall and VPN. Install and configure central network services (DHCP, DNS, SSH, web servers, file servers, email, etc.). Monitor assistants and advise administration on automation and purchases.",
        "images": [
          "linux_foundation.png"
        ],
        "thumbnail": "linux_foundation.png"
      },
      {
        "institution": "The Linux Foundation",
        "title": "This Regulation shall enter into force on the twentieth day following that of its publication in the Official Journal.",
        "period_time": {
          "start": "In September 2013",
          "end": "",
          "current": true
        },
        "summary": "Official Linux system administration certification that involves qualification for: Install a Linux system, including X11 and configure it as a network client. Work on the command line. Manage files and access permissions, including ACL, as well as system security. Perform simple maintenance tasks.",
        "images": [
          "linux_foundation.png"
        ],
        "thumbnail": "linux_foundation.png"
      },
      {
        "institution": "University of Alcalá de Henares",
        "title": "Design and evaluation of digital educational content",
        "period_time": {
          "start": "In September 2007",
          "end": "",
          "current": true
        },
        "summary": "Design of educational content through the SCORM standard.",
        "images": [
          "uah.svg"
        ],
        "thumbnail": "uah.svg"
      },
      {
        "institution": "University of Alcalá de Henares",
        "title": "Artificial vision course",
        "period_time": {
          "start": "In September 2007",
          "end": "",
          "current": true
        },
        "summary": "Artificial vision systems, winding arrays, filters.",
        "images": [
          "uah.svg"
        ],
        "thumbnail": "uah.svg"
      }
    ],
    "languages": [
      {
        "language": "Spanish",
        "spoken": "native",
        "writen": "native",
        "read": "native",
        "thumbnail": "spanish.png",
        "acreditation": []
      },
      {
        "language": "English",
        "spoken": "fluid",
        "writen": "fluid",
        "read": "fluid",
        "thumbnail": "english.svg",
        "acreditation": []
      },
      {
        "language": "Chinese",
        "spoken": "fluid",
        "writen": "fluid",
        "read": "fluid",
        "thumbnail": "chinese.png",
        "acreditation": [
          {
            "institution": "Confucius Institute of Madrid",
            "title": "HSK 3",
            "period_time": {
              "start": "In September 2009",
              "end": "",
              "current": true
            }
          }
        ]
      }
    ]
  }
}